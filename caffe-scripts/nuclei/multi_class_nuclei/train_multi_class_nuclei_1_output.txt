I1023 23:10:40.445260 21451 caffe.cpp:184] Using GPUs 0
I1023 23:10:40.656354 21451 solver.cpp:54] Initializing solver from parameters: 
test_iter: 70
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 20000
snapshot: 10000
snapshot_prefix: "examples/nuclei/multi_class_nuclei/multi_class_nuclei_1"
solver_mode: GPU
device_id: 0
net: "examples/nuclei/multi_class_nuclei/multi_class_nuclei_train_test.prototxt"
I1023 23:10:40.656507 21451 solver.cpp:97] Creating training net from net file: examples/nuclei/multi_class_nuclei/multi_class_nuclei_train_test.prototxt
I1023 23:10:40.656920 21451 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer nuclei
I1023 23:10:40.656949 21451 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1023 23:10:40.657070 21451 net.cpp:50] Initializing net from parameters: 
name: "NULCEI_quick"
state {
  phase: TRAIN
}
layer {
  name: "nuclei"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  image_data_param {
    source: "/home/sanuj/Projects/BTP/data/10_class_images/train.txt"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 6
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip_1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip_2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1023 23:10:40.657158 21451 layer_factory.hpp:76] Creating layer nuclei
I1023 23:10:40.657222 21451 net.cpp:110] Creating Layer nuclei
I1023 23:10:40.657238 21451 net.cpp:433] nuclei -> data
I1023 23:10:40.657287 21451 net.cpp:433] nuclei -> label
I1023 23:10:40.657311 21451 image_data_layer.cpp:37] Opening file /home/sanuj/Projects/BTP/data/10_class_images/train.txt
I1023 23:10:40.707794 21451 image_data_layer.cpp:52] A total of 90961 images.
I1023 23:10:40.723912 21451 image_data_layer.cpp:79] output data size: 100,3,33,33
I1023 23:10:40.730079 21451 net.cpp:155] Setting up nuclei
I1023 23:10:40.730183 21451 net.cpp:163] Top shape: 100 3 33 33 (326700)
I1023 23:10:40.730218 21451 net.cpp:163] Top shape: 100 (100)
I1023 23:10:40.730250 21451 layer_factory.hpp:76] Creating layer conv1
I1023 23:10:40.730295 21451 net.cpp:110] Creating Layer conv1
I1023 23:10:40.730322 21451 net.cpp:477] conv1 <- data
I1023 23:10:40.730358 21451 net.cpp:433] conv1 -> conv1
I1023 23:10:40.731848 21451 net.cpp:155] Setting up conv1
I1023 23:10:40.731946 21451 net.cpp:163] Top shape: 100 48 30 30 (4320000)
I1023 23:10:40.731992 21451 layer_factory.hpp:76] Creating layer pool1
I1023 23:10:40.732033 21451 net.cpp:110] Creating Layer pool1
I1023 23:10:40.732059 21451 net.cpp:477] pool1 <- conv1
I1023 23:10:40.732092 21451 net.cpp:433] pool1 -> pool1
I1023 23:10:40.732200 21451 net.cpp:155] Setting up pool1
I1023 23:10:40.732234 21451 net.cpp:163] Top shape: 100 48 15 15 (1080000)
I1023 23:10:40.732259 21451 layer_factory.hpp:76] Creating layer relu1
I1023 23:10:40.732292 21451 net.cpp:110] Creating Layer relu1
I1023 23:10:40.732318 21451 net.cpp:477] relu1 <- pool1
I1023 23:10:40.732343 21451 net.cpp:419] relu1 -> pool1 (in-place)
I1023 23:10:40.732373 21451 net.cpp:155] Setting up relu1
I1023 23:10:40.732399 21451 net.cpp:163] Top shape: 100 48 15 15 (1080000)
I1023 23:10:40.732421 21451 layer_factory.hpp:76] Creating layer conv2
I1023 23:10:40.732453 21451 net.cpp:110] Creating Layer conv2
I1023 23:10:40.732476 21451 net.cpp:477] conv2 <- pool1
I1023 23:10:40.732504 21451 net.cpp:433] conv2 -> conv2
I1023 23:10:40.737747 21451 net.cpp:155] Setting up conv2
I1023 23:10:40.737833 21451 net.cpp:163] Top shape: 100 48 10 10 (480000)
I1023 23:10:40.737874 21451 layer_factory.hpp:76] Creating layer relu2
I1023 23:10:40.737910 21451 net.cpp:110] Creating Layer relu2
I1023 23:10:40.737936 21451 net.cpp:477] relu2 <- conv2
I1023 23:10:40.737969 21451 net.cpp:419] relu2 -> conv2 (in-place)
I1023 23:10:40.738004 21451 net.cpp:155] Setting up relu2
I1023 23:10:40.738034 21451 net.cpp:163] Top shape: 100 48 10 10 (480000)
I1023 23:10:40.738067 21451 layer_factory.hpp:76] Creating layer pool2
I1023 23:10:40.738097 21451 net.cpp:110] Creating Layer pool2
I1023 23:10:40.738121 21451 net.cpp:477] pool2 <- conv2
I1023 23:10:40.738148 21451 net.cpp:433] pool2 -> pool2
I1023 23:10:40.738234 21451 net.cpp:155] Setting up pool2
I1023 23:10:40.738268 21451 net.cpp:163] Top shape: 100 48 5 5 (120000)
I1023 23:10:40.738294 21451 layer_factory.hpp:76] Creating layer ip_1
I1023 23:10:40.738327 21451 net.cpp:110] Creating Layer ip_1
I1023 23:10:40.738351 21451 net.cpp:477] ip_1 <- pool2
I1023 23:10:40.738389 21451 net.cpp:433] ip_1 -> ip1
I1023 23:10:40.742691 21451 net.cpp:155] Setting up ip_1
I1023 23:10:40.742807 21451 net.cpp:163] Top shape: 100 48 (4800)
I1023 23:10:40.742852 21451 layer_factory.hpp:76] Creating layer relu1
I1023 23:10:40.742892 21451 net.cpp:110] Creating Layer relu1
I1023 23:10:40.742915 21451 net.cpp:477] relu1 <- ip1
I1023 23:10:40.742949 21451 net.cpp:419] relu1 -> ip1 (in-place)
I1023 23:10:40.742982 21451 net.cpp:155] Setting up relu1
I1023 23:10:40.743010 21451 net.cpp:163] Top shape: 100 48 (4800)
I1023 23:10:40.743033 21451 layer_factory.hpp:76] Creating layer ip_2
I1023 23:10:40.743065 21451 net.cpp:110] Creating Layer ip_2
I1023 23:10:40.743094 21451 net.cpp:477] ip_2 <- ip1
I1023 23:10:40.743129 21451 net.cpp:433] ip_2 -> ip2
I1023 23:10:40.743342 21451 net.cpp:155] Setting up ip_2
I1023 23:10:40.743379 21451 net.cpp:163] Top shape: 100 10 (1000)
I1023 23:10:40.743410 21451 layer_factory.hpp:76] Creating layer loss
I1023 23:10:40.743444 21451 net.cpp:110] Creating Layer loss
I1023 23:10:40.743468 21451 net.cpp:477] loss <- ip2
I1023 23:10:40.743494 21451 net.cpp:477] loss <- label
I1023 23:10:40.743526 21451 net.cpp:433] loss -> loss
I1023 23:10:40.743563 21451 layer_factory.hpp:76] Creating layer loss
I1023 23:10:40.743805 21451 net.cpp:155] Setting up loss
I1023 23:10:40.743846 21451 net.cpp:163] Top shape: (1)
I1023 23:10:40.743873 21451 net.cpp:168]     with loss weight 1
I1023 23:10:40.743921 21451 net.cpp:236] loss needs backward computation.
I1023 23:10:40.743947 21451 net.cpp:236] ip_2 needs backward computation.
I1023 23:10:40.743969 21451 net.cpp:236] relu1 needs backward computation.
I1023 23:10:40.743998 21451 net.cpp:236] ip_1 needs backward computation.
I1023 23:10:40.744022 21451 net.cpp:236] pool2 needs backward computation.
I1023 23:10:40.744048 21451 net.cpp:236] relu2 needs backward computation.
I1023 23:10:40.744084 21451 net.cpp:236] conv2 needs backward computation.
I1023 23:10:40.744123 21451 net.cpp:236] relu1 needs backward computation.
I1023 23:10:40.744153 21451 net.cpp:236] pool1 needs backward computation.
I1023 23:10:40.744176 21451 net.cpp:236] conv1 needs backward computation.
I1023 23:10:40.744200 21451 net.cpp:240] nuclei does not need backward computation.
I1023 23:10:40.744226 21451 net.cpp:283] This network produces output loss
I1023 23:10:40.744264 21451 net.cpp:297] Network initialization done.
I1023 23:10:40.744289 21451 net.cpp:298] Memory required for data: 31589604
I1023 23:10:40.744828 21451 solver.cpp:187] Creating test net (#0) specified by net file: examples/nuclei/multi_class_nuclei/multi_class_nuclei_train_test.prototxt
I1023 23:10:40.744915 21451 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer nuclei
I1023 23:10:40.745108 21451 net.cpp:50] Initializing net from parameters: 
name: "NULCEI_quick"
state {
  phase: TEST
}
layer {
  name: "nuclei"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  image_data_param {
    source: "/home/sanuj/Projects/BTP/data/10_class_images/test.txt"
    batch_size: 500
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 6
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip_1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip_2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1023 23:10:40.745882 21451 layer_factory.hpp:76] Creating layer nuclei
I1023 23:10:40.745931 21451 net.cpp:110] Creating Layer nuclei
I1023 23:10:40.745959 21451 net.cpp:433] nuclei -> data
I1023 23:10:40.745990 21451 net.cpp:433] nuclei -> label
I1023 23:10:40.746021 21451 image_data_layer.cpp:37] Opening file /home/sanuj/Projects/BTP/data/10_class_images/test.txt
I1023 23:10:40.777328 21451 image_data_layer.cpp:52] A total of 34999 images.
I1023 23:10:40.777603 21451 image_data_layer.cpp:79] output data size: 500,3,33,33
I1023 23:10:40.805501 21451 net.cpp:155] Setting up nuclei
I1023 23:10:40.805608 21451 net.cpp:163] Top shape: 500 3 33 33 (1633500)
I1023 23:10:40.805656 21451 net.cpp:163] Top shape: 500 (500)
I1023 23:10:40.805696 21451 layer_factory.hpp:76] Creating layer label_nuclei_1_split
I1023 23:10:40.805753 21451 net.cpp:110] Creating Layer label_nuclei_1_split
I1023 23:10:40.805795 21451 net.cpp:477] label_nuclei_1_split <- label
I1023 23:10:40.805825 21451 net.cpp:433] label_nuclei_1_split -> label_nuclei_1_split_0
I1023 23:10:40.805860 21451 net.cpp:433] label_nuclei_1_split -> label_nuclei_1_split_1
I1023 23:10:40.805949 21451 net.cpp:155] Setting up label_nuclei_1_split
I1023 23:10:40.805979 21451 net.cpp:163] Top shape: 500 (500)
I1023 23:10:40.806005 21451 net.cpp:163] Top shape: 500 (500)
I1023 23:10:40.806030 21451 layer_factory.hpp:76] Creating layer conv1
I1023 23:10:40.806062 21451 net.cpp:110] Creating Layer conv1
I1023 23:10:40.806087 21451 net.cpp:477] conv1 <- data
I1023 23:10:40.806116 21451 net.cpp:433] conv1 -> conv1
I1023 23:10:40.806535 21451 net.cpp:155] Setting up conv1
I1023 23:10:40.806568 21451 net.cpp:163] Top shape: 500 48 30 30 (21600000)
I1023 23:10:40.806605 21451 layer_factory.hpp:76] Creating layer pool1
I1023 23:10:40.806633 21451 net.cpp:110] Creating Layer pool1
I1023 23:10:40.806656 21451 net.cpp:477] pool1 <- conv1
I1023 23:10:40.806682 21451 net.cpp:433] pool1 -> pool1
I1023 23:10:40.806768 21451 net.cpp:155] Setting up pool1
I1023 23:10:40.806802 21451 net.cpp:163] Top shape: 500 48 15 15 (5400000)
I1023 23:10:40.806830 21451 layer_factory.hpp:76] Creating layer relu1
I1023 23:10:40.806861 21451 net.cpp:110] Creating Layer relu1
I1023 23:10:40.806890 21451 net.cpp:477] relu1 <- pool1
I1023 23:10:40.806921 21451 net.cpp:419] relu1 -> pool1 (in-place)
I1023 23:10:40.806953 21451 net.cpp:155] Setting up relu1
I1023 23:10:40.806982 21451 net.cpp:163] Top shape: 500 48 15 15 (5400000)
I1023 23:10:40.807008 21451 layer_factory.hpp:76] Creating layer conv2
I1023 23:10:40.807044 21451 net.cpp:110] Creating Layer conv2
I1023 23:10:40.807070 21451 net.cpp:477] conv2 <- pool1
I1023 23:10:40.807098 21451 net.cpp:433] conv2 -> conv2
I1023 23:10:40.815768 21451 net.cpp:155] Setting up conv2
I1023 23:10:40.815964 21451 net.cpp:163] Top shape: 500 48 10 10 (2400000)
I1023 23:10:40.816097 21451 layer_factory.hpp:76] Creating layer relu2
I1023 23:10:40.816217 21451 net.cpp:110] Creating Layer relu2
I1023 23:10:40.816329 21451 net.cpp:477] relu2 <- conv2
I1023 23:10:40.816445 21451 net.cpp:419] relu2 -> conv2 (in-place)
I1023 23:10:40.816565 21451 net.cpp:155] Setting up relu2
I1023 23:10:40.816684 21451 net.cpp:163] Top shape: 500 48 10 10 (2400000)
I1023 23:10:40.816793 21451 layer_factory.hpp:76] Creating layer pool2
I1023 23:10:40.816911 21451 net.cpp:110] Creating Layer pool2
I1023 23:10:40.817023 21451 net.cpp:477] pool2 <- conv2
I1023 23:10:40.817137 21451 net.cpp:433] pool2 -> pool2
I1023 23:10:40.817327 21451 net.cpp:155] Setting up pool2
I1023 23:10:40.817446 21451 net.cpp:163] Top shape: 500 48 5 5 (600000)
I1023 23:10:40.817556 21451 layer_factory.hpp:76] Creating layer ip_1
I1023 23:10:40.817689 21451 net.cpp:110] Creating Layer ip_1
I1023 23:10:40.817805 21451 net.cpp:477] ip_1 <- pool2
I1023 23:10:40.817919 21451 net.cpp:433] ip_1 -> ip1
I1023 23:10:40.821064 21451 net.cpp:155] Setting up ip_1
I1023 23:10:40.821238 21451 net.cpp:163] Top shape: 500 48 (24000)
I1023 23:10:40.821367 21451 layer_factory.hpp:76] Creating layer relu1
I1023 23:10:40.821485 21451 net.cpp:110] Creating Layer relu1
I1023 23:10:40.821596 21451 net.cpp:477] relu1 <- ip1
I1023 23:10:40.821727 21451 net.cpp:419] relu1 -> ip1 (in-place)
I1023 23:10:40.821846 21451 net.cpp:155] Setting up relu1
I1023 23:10:40.821961 21451 net.cpp:163] Top shape: 500 48 (24000)
I1023 23:10:40.822072 21451 layer_factory.hpp:76] Creating layer ip_2
I1023 23:10:40.822187 21451 net.cpp:110] Creating Layer ip_2
I1023 23:10:40.822299 21451 net.cpp:477] ip_2 <- ip1
I1023 23:10:40.822412 21451 net.cpp:433] ip_2 -> ip2
I1023 23:10:40.822737 21451 net.cpp:155] Setting up ip_2
I1023 23:10:40.822863 21451 net.cpp:163] Top shape: 500 10 (5000)
I1023 23:10:40.822983 21451 layer_factory.hpp:76] Creating layer ip2_ip_2_0_split
I1023 23:10:40.823097 21451 net.cpp:110] Creating Layer ip2_ip_2_0_split
I1023 23:10:40.823210 21451 net.cpp:477] ip2_ip_2_0_split <- ip2
I1023 23:10:40.823336 21451 net.cpp:433] ip2_ip_2_0_split -> ip2_ip_2_0_split_0
I1023 23:10:40.823472 21451 net.cpp:433] ip2_ip_2_0_split -> ip2_ip_2_0_split_1
I1023 23:10:40.823711 21451 net.cpp:155] Setting up ip2_ip_2_0_split
I1023 23:10:40.823843 21451 net.cpp:163] Top shape: 500 10 (5000)
I1023 23:10:40.823876 21451 net.cpp:163] Top shape: 500 10 (5000)
I1023 23:10:40.823909 21451 layer_factory.hpp:76] Creating layer accuracy
I1023 23:10:40.823943 21451 net.cpp:110] Creating Layer accuracy
I1023 23:10:40.823971 21451 net.cpp:477] accuracy <- ip2_ip_2_0_split_0
I1023 23:10:40.823999 21451 net.cpp:477] accuracy <- label_nuclei_1_split_0
I1023 23:10:40.824043 21451 net.cpp:433] accuracy -> accuracy
I1023 23:10:40.824082 21451 net.cpp:155] Setting up accuracy
I1023 23:10:40.824112 21451 net.cpp:163] Top shape: (1)
I1023 23:10:40.824138 21451 layer_factory.hpp:76] Creating layer loss
I1023 23:10:40.824180 21451 net.cpp:110] Creating Layer loss
I1023 23:10:40.824208 21451 net.cpp:477] loss <- ip2_ip_2_0_split_1
I1023 23:10:40.824236 21451 net.cpp:477] loss <- label_nuclei_1_split_1
I1023 23:10:40.824272 21451 net.cpp:433] loss -> loss
I1023 23:10:40.824309 21451 layer_factory.hpp:76] Creating layer loss
I1023 23:10:40.825122 21451 net.cpp:155] Setting up loss
I1023 23:10:40.825191 21451 net.cpp:163] Top shape: (1)
I1023 23:10:40.825222 21451 net.cpp:168]     with loss weight 1
I1023 23:10:40.825261 21451 net.cpp:236] loss needs backward computation.
I1023 23:10:40.825291 21451 net.cpp:240] accuracy does not need backward computation.
I1023 23:10:40.825322 21451 net.cpp:236] ip2_ip_2_0_split needs backward computation.
I1023 23:10:40.825348 21451 net.cpp:236] ip_2 needs backward computation.
I1023 23:10:40.825374 21451 net.cpp:236] relu1 needs backward computation.
I1023 23:10:40.825400 21451 net.cpp:236] ip_1 needs backward computation.
I1023 23:10:40.825430 21451 net.cpp:236] pool2 needs backward computation.
I1023 23:10:40.825456 21451 net.cpp:236] relu2 needs backward computation.
I1023 23:10:40.825481 21451 net.cpp:236] conv2 needs backward computation.
I1023 23:10:40.825520 21451 net.cpp:236] relu1 needs backward computation.
I1023 23:10:40.825548 21451 net.cpp:236] pool1 needs backward computation.
I1023 23:10:40.825575 21451 net.cpp:236] conv1 needs backward computation.
I1023 23:10:40.825603 21451 net.cpp:240] label_nuclei_1_split does not need backward computation.
I1023 23:10:40.825644 21451 net.cpp:240] nuclei does not need backward computation.
I1023 23:10:40.825673 21451 net.cpp:283] This network produces output accuracy
I1023 23:10:40.825702 21451 net.cpp:283] This network produces output loss
I1023 23:10:40.825743 21451 net.cpp:297] Network initialization done.
I1023 23:10:40.825769 21451 net.cpp:298] Memory required for data: 157992008
I1023 23:10:40.825870 21451 solver.cpp:66] Solver scaffolding done.
I1023 23:10:40.826375 21451 caffe.cpp:212] Starting Optimization
I1023 23:10:40.826421 21451 solver.cpp:294] Solving NULCEI_quick
I1023 23:10:40.826447 21451 solver.cpp:295] Learning Rate Policy: step
I1023 23:10:40.827172 21451 solver.cpp:347] Iteration 0, Testing net (#0)
I1023 23:10:40.827425 21451 blocking_queue.cpp:50] Data layer prefetch queue empty
I1023 23:10:55.620676 21451 solver.cpp:415]     Test net output #0: accuracy = 0.102343
I1023 23:10:55.620723 21451 solver.cpp:415]     Test net output #1: loss = 2.3046 (* 1 = 2.3046 loss)
I1023 23:10:55.690834 21451 solver.cpp:243] Iteration 0, loss = 2.30531
I1023 23:10:55.690881 21451 solver.cpp:259]     Train net output #0: loss = 2.30531 (* 1 = 2.30531 loss)
I1023 23:10:55.690910 21451 solver.cpp:590] Iteration 0, lr = 0.001
I1023 23:11:07.950875 21451 solver.cpp:243] Iteration 100, loss = 1.75316
I1023 23:11:07.950924 21451 solver.cpp:259]     Train net output #0: loss = 1.75316 (* 1 = 1.75316 loss)
I1023 23:11:07.950937 21451 solver.cpp:590] Iteration 100, lr = 0.001
I1023 23:11:19.902711 21451 solver.cpp:243] Iteration 200, loss = 1.9882
I1023 23:11:19.902832 21451 solver.cpp:259]     Train net output #0: loss = 1.9882 (* 1 = 1.9882 loss)
I1023 23:11:19.902844 21451 solver.cpp:590] Iteration 200, lr = 0.001
I1023 23:11:32.346328 21451 solver.cpp:243] Iteration 300, loss = 1.57661
I1023 23:11:32.346375 21451 solver.cpp:259]     Train net output #0: loss = 1.57661 (* 1 = 1.57661 loss)
I1023 23:11:32.346386 21451 solver.cpp:590] Iteration 300, lr = 0.001
I1023 23:11:44.753582 21451 solver.cpp:243] Iteration 400, loss = 1.26086
I1023 23:11:44.753618 21451 solver.cpp:259]     Train net output #0: loss = 1.26086 (* 1 = 1.26086 loss)
I1023 23:11:44.753633 21451 solver.cpp:590] Iteration 400, lr = 0.001
I1023 23:11:57.135995 21451 solver.cpp:243] Iteration 500, loss = 1.17421
I1023 23:11:57.136064 21451 solver.cpp:259]     Train net output #0: loss = 1.17421 (* 1 = 1.17421 loss)
I1023 23:11:57.136072 21451 solver.cpp:590] Iteration 500, lr = 0.001
I1023 23:12:09.714833 21451 solver.cpp:243] Iteration 600, loss = 1.37565
I1023 23:12:09.714866 21451 solver.cpp:259]     Train net output #0: loss = 1.37565 (* 1 = 1.37565 loss)
I1023 23:12:09.714877 21451 solver.cpp:590] Iteration 600, lr = 0.001
I1023 23:12:22.531615 21451 solver.cpp:243] Iteration 700, loss = 1.49975
I1023 23:12:22.531646 21451 solver.cpp:259]     Train net output #0: loss = 1.49975 (* 1 = 1.49975 loss)
I1023 23:12:22.531654 21451 solver.cpp:590] Iteration 700, lr = 0.001
I1023 23:12:34.596884 21451 solver.cpp:243] Iteration 800, loss = 1.08652
I1023 23:12:34.596948 21451 solver.cpp:259]     Train net output #0: loss = 1.08652 (* 1 = 1.08652 loss)
I1023 23:12:34.596959 21451 solver.cpp:590] Iteration 800, lr = 0.001
I1023 23:12:46.753504 21451 solver.cpp:243] Iteration 900, loss = 1.07672
I1023 23:12:46.753537 21451 solver.cpp:259]     Train net output #0: loss = 1.07672 (* 1 = 1.07672 loss)
I1023 23:12:46.753546 21451 solver.cpp:590] Iteration 900, lr = 0.001
I1023 23:12:59.422008 21451 solver.cpp:347] Iteration 1000, Testing net (#0)
I1023 23:13:14.386807 21451 solver.cpp:415]     Test net output #0: accuracy = 0.450971
I1023 23:13:14.386909 21451 solver.cpp:415]     Test net output #1: loss = 1.38541 (* 1 = 1.38541 loss)
I1023 23:13:14.445483 21451 solver.cpp:243] Iteration 1000, loss = 1.43029
I1023 23:13:14.445519 21451 solver.cpp:259]     Train net output #0: loss = 1.43029 (* 1 = 1.43029 loss)
I1023 23:13:14.445528 21451 solver.cpp:590] Iteration 1000, lr = 0.001
I1023 23:13:26.518925 21451 solver.cpp:243] Iteration 1100, loss = 0.97628
I1023 23:13:26.518961 21451 solver.cpp:259]     Train net output #0: loss = 0.97628 (* 1 = 0.97628 loss)
I1023 23:13:26.518970 21451 solver.cpp:590] Iteration 1100, lr = 0.001
I1023 23:13:38.886380 21451 solver.cpp:243] Iteration 1200, loss = 0.937709
I1023 23:13:38.886410 21451 solver.cpp:259]     Train net output #0: loss = 0.937709 (* 1 = 0.937709 loss)
I1023 23:13:38.886420 21451 solver.cpp:590] Iteration 1200, lr = 0.001
I1023 23:13:51.022222 21451 solver.cpp:243] Iteration 1300, loss = 0.98683
I1023 23:13:51.022275 21451 solver.cpp:259]     Train net output #0: loss = 0.98683 (* 1 = 0.98683 loss)
I1023 23:13:51.022284 21451 solver.cpp:590] Iteration 1300, lr = 0.001
I1023 23:14:03.646458 21451 solver.cpp:243] Iteration 1400, loss = 1.03947
I1023 23:14:03.646494 21451 solver.cpp:259]     Train net output #0: loss = 1.03947 (* 1 = 1.03947 loss)
I1023 23:14:03.646502 21451 solver.cpp:590] Iteration 1400, lr = 0.001
I1023 23:14:16.117354 21451 solver.cpp:243] Iteration 1500, loss = 1.04149
I1023 23:14:16.117406 21451 solver.cpp:259]     Train net output #0: loss = 1.04149 (* 1 = 1.04149 loss)
I1023 23:14:16.117422 21451 solver.cpp:590] Iteration 1500, lr = 0.001
I1023 23:14:28.025605 21451 solver.cpp:243] Iteration 1600, loss = 0.929159
I1023 23:14:28.025692 21451 solver.cpp:259]     Train net output #0: loss = 0.929159 (* 1 = 0.929159 loss)
I1023 23:14:28.025708 21451 solver.cpp:590] Iteration 1600, lr = 0.001
I1023 23:14:39.901286 21451 solver.cpp:243] Iteration 1700, loss = 0.748946
I1023 23:14:39.901336 21451 solver.cpp:259]     Train net output #0: loss = 0.748946 (* 1 = 0.748946 loss)
I1023 23:14:39.901352 21451 solver.cpp:590] Iteration 1700, lr = 0.001
I1023 23:14:51.787905 21451 solver.cpp:243] Iteration 1800, loss = 0.709587
I1023 23:14:51.787950 21451 solver.cpp:259]     Train net output #0: loss = 0.709587 (* 1 = 0.709587 loss)
I1023 23:14:51.787967 21451 solver.cpp:590] Iteration 1800, lr = 0.001
I1023 23:15:03.640393 21451 solver.cpp:243] Iteration 1900, loss = 0.691555
I1023 23:15:03.640543 21451 solver.cpp:259]     Train net output #0: loss = 0.691555 (* 1 = 0.691555 loss)
I1023 23:15:03.640672 21451 solver.cpp:590] Iteration 1900, lr = 0.001
I1023 23:15:15.370569 21451 solver.cpp:347] Iteration 2000, Testing net (#0)
I1023 23:15:29.935159 21451 solver.cpp:415]     Test net output #0: accuracy = 0.714914
I1023 23:15:29.935209 21451 solver.cpp:415]     Test net output #1: loss = 0.758767 (* 1 = 0.758767 loss)
I1023 23:15:30.000075 21451 solver.cpp:243] Iteration 2000, loss = 0.688559
I1023 23:15:30.000131 21451 solver.cpp:259]     Train net output #0: loss = 0.688559 (* 1 = 0.688559 loss)
I1023 23:15:30.000149 21451 solver.cpp:590] Iteration 2000, lr = 0.001
I1023 23:15:41.848302 21451 solver.cpp:243] Iteration 2100, loss = 0.7406
I1023 23:15:41.848397 21451 solver.cpp:259]     Train net output #0: loss = 0.7406 (* 1 = 0.7406 loss)
I1023 23:15:41.848414 21451 solver.cpp:590] Iteration 2100, lr = 0.001
I1023 23:15:53.696485 21451 solver.cpp:243] Iteration 2200, loss = 0.575303
I1023 23:15:53.696537 21451 solver.cpp:259]     Train net output #0: loss = 0.575303 (* 1 = 0.575303 loss)
I1023 23:15:53.696550 21451 solver.cpp:590] Iteration 2200, lr = 0.001
I1023 23:16:05.558024 21451 solver.cpp:243] Iteration 2300, loss = 0.845953
I1023 23:16:05.558074 21451 solver.cpp:259]     Train net output #0: loss = 0.845953 (* 1 = 0.845953 loss)
I1023 23:16:05.558090 21451 solver.cpp:590] Iteration 2300, lr = 0.001
I1023 23:16:17.409739 21451 solver.cpp:243] Iteration 2400, loss = 0.820749
I1023 23:16:17.409847 21451 solver.cpp:259]     Train net output #0: loss = 0.820749 (* 1 = 0.820749 loss)
I1023 23:16:17.409863 21451 solver.cpp:590] Iteration 2400, lr = 0.001
I1023 23:16:29.270042 21451 solver.cpp:243] Iteration 2500, loss = 0.699257
I1023 23:16:29.270093 21451 solver.cpp:259]     Train net output #0: loss = 0.699257 (* 1 = 0.699257 loss)
I1023 23:16:29.270170 21451 solver.cpp:590] Iteration 2500, lr = 0.001
I1023 23:16:41.120412 21451 solver.cpp:243] Iteration 2600, loss = 0.765985
I1023 23:16:41.120462 21451 solver.cpp:259]     Train net output #0: loss = 0.765985 (* 1 = 0.765985 loss)
I1023 23:16:41.120478 21451 solver.cpp:590] Iteration 2600, lr = 0.001
I1023 23:16:53.215463 21451 solver.cpp:243] Iteration 2700, loss = 1.11328
I1023 23:16:53.215606 21451 solver.cpp:259]     Train net output #0: loss = 1.11328 (* 1 = 1.11328 loss)
I1023 23:16:53.215622 21451 solver.cpp:590] Iteration 2700, lr = 0.001
I1023 23:17:05.297870 21451 solver.cpp:243] Iteration 2800, loss = 1.30302
I1023 23:17:05.297921 21451 solver.cpp:259]     Train net output #0: loss = 1.30302 (* 1 = 1.30302 loss)
I1023 23:17:05.297937 21451 solver.cpp:590] Iteration 2800, lr = 0.001
I1023 23:17:17.599298 21451 solver.cpp:243] Iteration 2900, loss = 0.645246
I1023 23:17:17.599344 21451 solver.cpp:259]     Train net output #0: loss = 0.645246 (* 1 = 0.645246 loss)
I1023 23:17:17.599359 21451 solver.cpp:590] Iteration 2900, lr = 0.001
I1023 23:17:29.818742 21451 solver.cpp:347] Iteration 3000, Testing net (#0)
I1023 23:17:44.389644 21451 solver.cpp:415]     Test net output #0: accuracy = 0.762172
I1023 23:17:44.389691 21451 solver.cpp:415]     Test net output #1: loss = 0.640214 (* 1 = 0.640214 loss)
I1023 23:17:44.450454 21451 solver.cpp:243] Iteration 3000, loss = 0.609746
I1023 23:17:44.450503 21451 solver.cpp:259]     Train net output #0: loss = 0.609746 (* 1 = 0.609746 loss)
I1023 23:17:44.450518 21451 solver.cpp:590] Iteration 3000, lr = 0.001
I1023 23:17:56.375305 21451 solver.cpp:243] Iteration 3100, loss = 0.500813
I1023 23:17:56.375355 21451 solver.cpp:259]     Train net output #0: loss = 0.500813 (* 1 = 0.500813 loss)
I1023 23:17:56.375370 21451 solver.cpp:590] Iteration 3100, lr = 0.001
I1023 23:18:08.304317 21451 solver.cpp:243] Iteration 3200, loss = 0.677382
I1023 23:18:08.304428 21451 solver.cpp:259]     Train net output #0: loss = 0.677382 (* 1 = 0.677382 loss)
I1023 23:18:08.304445 21451 solver.cpp:590] Iteration 3200, lr = 0.001
I1023 23:18:20.217295 21451 solver.cpp:243] Iteration 3300, loss = 0.504144
I1023 23:18:20.217342 21451 solver.cpp:259]     Train net output #0: loss = 0.504144 (* 1 = 0.504144 loss)
I1023 23:18:20.217360 21451 solver.cpp:590] Iteration 3300, lr = 0.001
I1023 23:18:32.140782 21451 solver.cpp:243] Iteration 3400, loss = 0.850604
I1023 23:18:32.140836 21451 solver.cpp:259]     Train net output #0: loss = 0.850604 (* 1 = 0.850604 loss)
I1023 23:18:32.140851 21451 solver.cpp:590] Iteration 3400, lr = 0.001
I1023 23:18:44.043114 21451 solver.cpp:243] Iteration 3500, loss = 0.718072
I1023 23:18:44.043195 21451 solver.cpp:259]     Train net output #0: loss = 0.718072 (* 1 = 0.718072 loss)
I1023 23:18:44.043210 21451 solver.cpp:590] Iteration 3500, lr = 0.001
I1023 23:18:55.969056 21451 solver.cpp:243] Iteration 3600, loss = 0.582214
I1023 23:18:55.969105 21451 solver.cpp:259]     Train net output #0: loss = 0.582214 (* 1 = 0.582214 loss)
I1023 23:18:55.969122 21451 solver.cpp:590] Iteration 3600, lr = 0.001
I1023 23:19:07.908793 21451 solver.cpp:243] Iteration 3700, loss = 0.460967
I1023 23:19:07.908841 21451 solver.cpp:259]     Train net output #0: loss = 0.460967 (* 1 = 0.460967 loss)
I1023 23:19:07.908953 21451 solver.cpp:590] Iteration 3700, lr = 0.001
I1023 23:19:19.828029 21451 solver.cpp:243] Iteration 3800, loss = 0.568136
I1023 23:19:19.828126 21451 solver.cpp:259]     Train net output #0: loss = 0.568136 (* 1 = 0.568136 loss)
I1023 23:19:19.828143 21451 solver.cpp:590] Iteration 3800, lr = 0.001
I1023 23:19:31.737776 21451 solver.cpp:243] Iteration 3900, loss = 0.714078
I1023 23:19:31.737825 21451 solver.cpp:259]     Train net output #0: loss = 0.714078 (* 1 = 0.714078 loss)
I1023 23:19:31.737841 21451 solver.cpp:590] Iteration 3900, lr = 0.001
I1023 23:19:43.531869 21451 solver.cpp:347] Iteration 4000, Testing net (#0)
I1023 23:19:58.120919 21451 solver.cpp:415]     Test net output #0: accuracy = 0.787143
I1023 23:19:58.120980 21451 solver.cpp:415]     Test net output #1: loss = 0.577972 (* 1 = 0.577972 loss)
I1023 23:19:58.183956 21451 solver.cpp:243] Iteration 4000, loss = 0.614068
I1023 23:19:58.183989 21451 solver.cpp:259]     Train net output #0: loss = 0.614068 (* 1 = 0.614068 loss)
I1023 23:19:58.183996 21451 solver.cpp:590] Iteration 4000, lr = 0.001
I1023 23:20:10.240311 21451 solver.cpp:243] Iteration 4100, loss = 0.547731
I1023 23:20:10.240344 21451 solver.cpp:259]     Train net output #0: loss = 0.547731 (* 1 = 0.547731 loss)
I1023 23:20:10.240351 21451 solver.cpp:590] Iteration 4100, lr = 0.001
I1023 23:20:23.140679 21451 solver.cpp:243] Iteration 4200, loss = 0.643621
I1023 23:20:23.140728 21451 solver.cpp:259]     Train net output #0: loss = 0.643621 (* 1 = 0.643621 loss)
I1023 23:20:23.140744 21451 solver.cpp:590] Iteration 4200, lr = 0.001
I1023 23:20:35.600394 21451 solver.cpp:243] Iteration 4300, loss = 0.700037
I1023 23:20:35.600462 21451 solver.cpp:259]     Train net output #0: loss = 0.700037 (* 1 = 0.700037 loss)
I1023 23:20:35.600472 21451 solver.cpp:590] Iteration 4300, lr = 0.001
I1023 23:20:48.134100 21451 solver.cpp:243] Iteration 4400, loss = 0.506448
I1023 23:20:48.134140 21451 solver.cpp:259]     Train net output #0: loss = 0.506448 (* 1 = 0.506448 loss)
I1023 23:20:48.134150 21451 solver.cpp:590] Iteration 4400, lr = 0.001
I1023 23:20:59.990473 21451 solver.cpp:243] Iteration 4500, loss = 0.922185
I1023 23:20:59.990501 21451 solver.cpp:259]     Train net output #0: loss = 0.922185 (* 1 = 0.922185 loss)
I1023 23:20:59.990509 21451 solver.cpp:590] Iteration 4500, lr = 0.001
I1023 23:21:12.188428 21451 solver.cpp:243] Iteration 4600, loss = 0.593636
I1023 23:21:12.188508 21451 solver.cpp:259]     Train net output #0: loss = 0.593636 (* 1 = 0.593636 loss)
I1023 23:21:12.188516 21451 solver.cpp:590] Iteration 4600, lr = 0.001
I1023 23:21:24.025501 21451 solver.cpp:243] Iteration 4700, loss = 0.545754
I1023 23:21:24.025537 21451 solver.cpp:259]     Train net output #0: loss = 0.545754 (* 1 = 0.545754 loss)
I1023 23:21:24.025545 21451 solver.cpp:590] Iteration 4700, lr = 0.001
I1023 23:21:35.846948 21451 solver.cpp:243] Iteration 4800, loss = 0.533671
I1023 23:21:35.846983 21451 solver.cpp:259]     Train net output #0: loss = 0.533671 (* 1 = 0.533671 loss)
I1023 23:21:35.846998 21451 solver.cpp:590] Iteration 4800, lr = 0.001
I1023 23:21:47.684330 21451 solver.cpp:243] Iteration 4900, loss = 0.644893
I1023 23:21:47.684437 21451 solver.cpp:259]     Train net output #0: loss = 0.644893 (* 1 = 0.644893 loss)
I1023 23:21:47.684448 21451 solver.cpp:590] Iteration 4900, lr = 0.001
I1023 23:21:59.397248 21451 solver.cpp:347] Iteration 5000, Testing net (#0)
I1023 23:22:13.886872 21451 solver.cpp:415]     Test net output #0: accuracy = 0.794029
I1023 23:22:13.886900 21451 solver.cpp:415]     Test net output #1: loss = 0.575348 (* 1 = 0.575348 loss)
I1023 23:22:13.942847 21451 solver.cpp:243] Iteration 5000, loss = 0.438996
I1023 23:22:13.942878 21451 solver.cpp:259]     Train net output #0: loss = 0.438996 (* 1 = 0.438996 loss)
I1023 23:22:13.942888 21451 solver.cpp:590] Iteration 5000, lr = 0.001
I1023 23:22:25.774287 21451 solver.cpp:243] Iteration 5100, loss = 0.583481
I1023 23:22:25.774386 21451 solver.cpp:259]     Train net output #0: loss = 0.583481 (* 1 = 0.583481 loss)
I1023 23:22:25.774396 21451 solver.cpp:590] Iteration 5100, lr = 0.001
I1023 23:22:37.601125 21451 solver.cpp:243] Iteration 5200, loss = 0.738815
I1023 23:22:37.601155 21451 solver.cpp:259]     Train net output #0: loss = 0.738815 (* 1 = 0.738815 loss)
I1023 23:22:37.601162 21451 solver.cpp:590] Iteration 5200, lr = 0.001
I1023 23:22:49.740334 21451 solver.cpp:243] Iteration 5300, loss = 0.592436
I1023 23:22:49.740366 21451 solver.cpp:259]     Train net output #0: loss = 0.592436 (* 1 = 0.592436 loss)
I1023 23:22:49.740375 21451 solver.cpp:590] Iteration 5300, lr = 0.001
I1023 23:23:02.294215 21451 solver.cpp:243] Iteration 5400, loss = 0.693352
I1023 23:23:02.294286 21451 solver.cpp:259]     Train net output #0: loss = 0.693353 (* 1 = 0.693353 loss)
I1023 23:23:02.294296 21451 solver.cpp:590] Iteration 5400, lr = 0.001
I1023 23:23:15.354888 21451 solver.cpp:243] Iteration 5500, loss = 0.462044
I1023 23:23:15.354923 21451 solver.cpp:259]     Train net output #0: loss = 0.462044 (* 1 = 0.462044 loss)
I1023 23:23:15.354933 21451 solver.cpp:590] Iteration 5500, lr = 0.001
I1023 23:23:27.433818 21451 solver.cpp:243] Iteration 5600, loss = 0.437192
I1023 23:23:27.433848 21451 solver.cpp:259]     Train net output #0: loss = 0.437192 (* 1 = 0.437192 loss)
I1023 23:23:27.433856 21451 solver.cpp:590] Iteration 5600, lr = 0.001
I1023 23:23:39.252174 21451 solver.cpp:243] Iteration 5700, loss = 0.778165
I1023 23:23:39.252238 21451 solver.cpp:259]     Train net output #0: loss = 0.778165 (* 1 = 0.778165 loss)
I1023 23:23:39.252246 21451 solver.cpp:590] Iteration 5700, lr = 0.001
I1023 23:23:51.066926 21451 solver.cpp:243] Iteration 5800, loss = 0.530681
I1023 23:23:51.066957 21451 solver.cpp:259]     Train net output #0: loss = 0.530681 (* 1 = 0.530681 loss)
I1023 23:23:51.066965 21451 solver.cpp:590] Iteration 5800, lr = 0.001
I1023 23:24:02.887720 21451 solver.cpp:243] Iteration 5900, loss = 0.619663
I1023 23:24:02.887753 21451 solver.cpp:259]     Train net output #0: loss = 0.619663 (* 1 = 0.619663 loss)
I1023 23:24:02.887761 21451 solver.cpp:590] Iteration 5900, lr = 0.001
I1023 23:24:15.220582 21451 solver.cpp:347] Iteration 6000, Testing net (#0)
I1023 23:24:29.772837 21451 solver.cpp:415]     Test net output #0: accuracy = 0.751057
I1023 23:24:29.772871 21451 solver.cpp:415]     Test net output #1: loss = 0.614197 (* 1 = 0.614197 loss)
I1023 23:24:29.821285 21451 solver.cpp:243] Iteration 6000, loss = 0.572162
I1023 23:24:29.821312 21451 solver.cpp:259]     Train net output #0: loss = 0.572162 (* 1 = 0.572162 loss)
I1023 23:24:29.821321 21451 solver.cpp:590] Iteration 6000, lr = 0.001
I1023 23:24:41.641306 21451 solver.cpp:243] Iteration 6100, loss = 0.667868
I1023 23:24:41.641338 21451 solver.cpp:259]     Train net output #0: loss = 0.667868 (* 1 = 0.667868 loss)
I1023 23:24:41.641348 21451 solver.cpp:590] Iteration 6100, lr = 0.001
I1023 23:24:53.462968 21451 solver.cpp:243] Iteration 6200, loss = 0.486964
I1023 23:24:53.463075 21451 solver.cpp:259]     Train net output #0: loss = 0.486964 (* 1 = 0.486964 loss)
I1023 23:24:53.463084 21451 solver.cpp:590] Iteration 6200, lr = 0.001
I1023 23:25:05.288763 21451 solver.cpp:243] Iteration 6300, loss = 0.466982
I1023 23:25:05.288795 21451 solver.cpp:259]     Train net output #0: loss = 0.466982 (* 1 = 0.466982 loss)
I1023 23:25:05.288806 21451 solver.cpp:590] Iteration 6300, lr = 0.001
I1023 23:25:17.101090 21451 solver.cpp:243] Iteration 6400, loss = 0.466496
I1023 23:25:17.101125 21451 solver.cpp:259]     Train net output #0: loss = 0.466496 (* 1 = 0.466496 loss)
I1023 23:25:17.101135 21451 solver.cpp:590] Iteration 6400, lr = 0.001
I1023 23:25:28.921994 21451 solver.cpp:243] Iteration 6500, loss = 0.523881
I1023 23:25:28.922065 21451 solver.cpp:259]     Train net output #0: loss = 0.523881 (* 1 = 0.523881 loss)
I1023 23:25:28.922077 21451 solver.cpp:590] Iteration 6500, lr = 0.001
I1023 23:25:40.736937 21451 solver.cpp:243] Iteration 6600, loss = 0.486024
I1023 23:25:40.736964 21451 solver.cpp:259]     Train net output #0: loss = 0.486024 (* 1 = 0.486024 loss)
I1023 23:25:40.736973 21451 solver.cpp:590] Iteration 6600, lr = 0.001
I1023 23:25:52.567740 21451 solver.cpp:243] Iteration 6700, loss = 0.466314
I1023 23:25:52.567773 21451 solver.cpp:259]     Train net output #0: loss = 0.466314 (* 1 = 0.466314 loss)
I1023 23:25:52.567781 21451 solver.cpp:590] Iteration 6700, lr = 0.001
I1023 23:26:04.850090 21451 solver.cpp:243] Iteration 6800, loss = 0.458323
I1023 23:26:04.850137 21451 solver.cpp:259]     Train net output #0: loss = 0.458323 (* 1 = 0.458323 loss)
I1023 23:26:04.850145 21451 solver.cpp:590] Iteration 6800, lr = 0.001
I1023 23:26:16.947540 21451 solver.cpp:243] Iteration 6900, loss = 0.872342
I1023 23:26:16.947574 21451 solver.cpp:259]     Train net output #0: loss = 0.872342 (* 1 = 0.872342 loss)
I1023 23:26:16.947583 21451 solver.cpp:590] Iteration 6900, lr = 0.001
I1023 23:26:28.724305 21451 solver.cpp:347] Iteration 7000, Testing net (#0)
I1023 23:26:43.283363 21451 solver.cpp:415]     Test net output #0: accuracy = 0.820143
I1023 23:26:43.283421 21451 solver.cpp:415]     Test net output #1: loss = 0.489857 (* 1 = 0.489857 loss)
I1023 23:26:43.341997 21451 solver.cpp:243] Iteration 7000, loss = 0.359716
I1023 23:26:43.342038 21451 solver.cpp:259]     Train net output #0: loss = 0.359716 (* 1 = 0.359716 loss)
I1023 23:26:43.342051 21451 solver.cpp:590] Iteration 7000, lr = 0.001
I1023 23:26:55.240423 21451 solver.cpp:243] Iteration 7100, loss = 0.513458
I1023 23:26:55.240458 21451 solver.cpp:259]     Train net output #0: loss = 0.513458 (* 1 = 0.513458 loss)
I1023 23:26:55.240469 21451 solver.cpp:590] Iteration 7100, lr = 0.001
I1023 23:27:07.143820 21451 solver.cpp:243] Iteration 7200, loss = 0.57784
I1023 23:27:07.143854 21451 solver.cpp:259]     Train net output #0: loss = 0.57784 (* 1 = 0.57784 loss)
I1023 23:27:07.143867 21451 solver.cpp:590] Iteration 7200, lr = 0.001
I1023 23:27:19.041802 21451 solver.cpp:243] Iteration 7300, loss = 0.472475
I1023 23:27:19.041882 21451 solver.cpp:259]     Train net output #0: loss = 0.472475 (* 1 = 0.472475 loss)
I1023 23:27:19.041893 21451 solver.cpp:590] Iteration 7300, lr = 0.001
I1023 23:27:30.929560 21451 solver.cpp:243] Iteration 7400, loss = 0.367511
I1023 23:27:30.929594 21451 solver.cpp:259]     Train net output #0: loss = 0.367511 (* 1 = 0.367511 loss)
I1023 23:27:30.929610 21451 solver.cpp:590] Iteration 7400, lr = 0.001
I1023 23:27:43.114902 21451 solver.cpp:243] Iteration 7500, loss = 0.741073
I1023 23:27:43.114933 21451 solver.cpp:259]     Train net output #0: loss = 0.741073 (* 1 = 0.741073 loss)
I1023 23:27:43.114939 21451 solver.cpp:590] Iteration 7500, lr = 0.001
I1023 23:27:56.352780 21451 solver.cpp:243] Iteration 7600, loss = 0.421579
I1023 23:27:56.352885 21451 solver.cpp:259]     Train net output #0: loss = 0.421579 (* 1 = 0.421579 loss)
I1023 23:27:56.352898 21451 solver.cpp:590] Iteration 7600, lr = 0.001
I1023 23:28:12.188742 21451 solver.cpp:243] Iteration 7700, loss = 0.622956
I1023 23:28:12.188783 21451 solver.cpp:259]     Train net output #0: loss = 0.622956 (* 1 = 0.622956 loss)
I1023 23:28:12.188793 21451 solver.cpp:590] Iteration 7700, lr = 0.001
I1023 23:28:27.954943 21451 solver.cpp:243] Iteration 7800, loss = 0.428084
I1023 23:28:27.955016 21451 solver.cpp:259]     Train net output #0: loss = 0.428084 (* 1 = 0.428084 loss)
I1023 23:28:27.955031 21451 solver.cpp:590] Iteration 7800, lr = 0.001
I1023 23:28:43.736752 21451 solver.cpp:243] Iteration 7900, loss = 0.429731
I1023 23:28:43.736793 21451 solver.cpp:259]     Train net output #0: loss = 0.429731 (* 1 = 0.429731 loss)
I1023 23:28:43.736809 21451 solver.cpp:590] Iteration 7900, lr = 0.001
I1023 23:28:59.282593 21451 solver.cpp:347] Iteration 8000, Testing net (#0)
I1023 23:29:18.567687 21451 solver.cpp:415]     Test net output #0: accuracy = 0.8298
I1023 23:29:18.567723 21451 solver.cpp:415]     Test net output #1: loss = 0.472186 (* 1 = 0.472186 loss)
I1023 23:29:18.638770 21451 solver.cpp:243] Iteration 8000, loss = 0.291844
I1023 23:29:18.638804 21451 solver.cpp:259]     Train net output #0: loss = 0.291844 (* 1 = 0.291844 loss)
I1023 23:29:18.638813 21451 solver.cpp:590] Iteration 8000, lr = 0.001
I1023 23:29:34.908751 21451 solver.cpp:243] Iteration 8100, loss = 0.30178
I1023 23:29:34.908881 21451 solver.cpp:259]     Train net output #0: loss = 0.30178 (* 1 = 0.30178 loss)
I1023 23:29:34.908892 21451 solver.cpp:590] Iteration 8100, lr = 0.001
I1023 23:29:51.549857 21451 solver.cpp:243] Iteration 8200, loss = 0.387497
I1023 23:29:51.549902 21451 solver.cpp:259]     Train net output #0: loss = 0.387497 (* 1 = 0.387497 loss)
I1023 23:29:51.549916 21451 solver.cpp:590] Iteration 8200, lr = 0.001
I1023 23:30:08.601986 21451 solver.cpp:243] Iteration 8300, loss = 0.360362
I1023 23:30:08.602082 21451 solver.cpp:259]     Train net output #0: loss = 0.360362 (* 1 = 0.360362 loss)
I1023 23:30:08.602093 21451 solver.cpp:590] Iteration 8300, lr = 0.001
I1023 23:30:23.258024 21451 solver.cpp:243] Iteration 8400, loss = 0.501629
I1023 23:30:23.258071 21451 solver.cpp:259]     Train net output #0: loss = 0.501629 (* 1 = 0.501629 loss)
I1023 23:30:23.258088 21451 solver.cpp:590] Iteration 8400, lr = 0.001
I1023 23:30:35.530190 21451 solver.cpp:243] Iteration 8500, loss = 0.399163
I1023 23:30:35.530221 21451 solver.cpp:259]     Train net output #0: loss = 0.399163 (* 1 = 0.399163 loss)
I1023 23:30:35.530230 21451 solver.cpp:590] Iteration 8500, lr = 0.001
I1023 23:30:47.435068 21451 solver.cpp:243] Iteration 8600, loss = 0.322394
I1023 23:30:47.435130 21451 solver.cpp:259]     Train net output #0: loss = 0.322394 (* 1 = 0.322394 loss)
I1023 23:30:47.435138 21451 solver.cpp:590] Iteration 8600, lr = 0.001
I1023 23:30:59.342792 21451 solver.cpp:243] Iteration 8700, loss = 0.364499
I1023 23:30:59.342825 21451 solver.cpp:259]     Train net output #0: loss = 0.364499 (* 1 = 0.364499 loss)
I1023 23:30:59.342834 21451 solver.cpp:590] Iteration 8700, lr = 0.001
I1023 23:31:11.236181 21451 solver.cpp:243] Iteration 8800, loss = 0.478369
I1023 23:31:11.236212 21451 solver.cpp:259]     Train net output #0: loss = 0.478369 (* 1 = 0.478369 loss)
I1023 23:31:11.236219 21451 solver.cpp:590] Iteration 8800, lr = 0.001
I1023 23:31:23.987274 21451 solver.cpp:243] Iteration 8900, loss = 0.361364
I1023 23:31:23.987349 21451 solver.cpp:259]     Train net output #0: loss = 0.361364 (* 1 = 0.361364 loss)
I1023 23:31:23.987359 21451 solver.cpp:590] Iteration 8900, lr = 0.001
I1023 23:31:36.162813 21451 solver.cpp:347] Iteration 9000, Testing net (#0)
I1023 23:31:51.121064 21451 solver.cpp:415]     Test net output #0: accuracy = 0.865457
I1023 23:31:51.121094 21451 solver.cpp:415]     Test net output #1: loss = 0.384205 (* 1 = 0.384205 loss)
I1023 23:31:51.179407 21451 solver.cpp:243] Iteration 9000, loss = 0.346974
I1023 23:31:51.179440 21451 solver.cpp:259]     Train net output #0: loss = 0.346974 (* 1 = 0.346974 loss)
I1023 23:31:51.179450 21451 solver.cpp:590] Iteration 9000, lr = 0.001
I1023 23:32:03.086074 21451 solver.cpp:243] Iteration 9100, loss = 0.302535
I1023 23:32:03.086170 21451 solver.cpp:259]     Train net output #0: loss = 0.302535 (* 1 = 0.302535 loss)
I1023 23:32:03.086181 21451 solver.cpp:590] Iteration 9100, lr = 0.001
I1023 23:32:14.970417 21451 solver.cpp:243] Iteration 9200, loss = 0.62002
I1023 23:32:14.970451 21451 solver.cpp:259]     Train net output #0: loss = 0.62002 (* 1 = 0.62002 loss)
I1023 23:32:14.970460 21451 solver.cpp:590] Iteration 9200, lr = 0.001
I1023 23:32:26.969732 21451 solver.cpp:243] Iteration 9300, loss = 0.450449
I1023 23:32:26.969769 21451 solver.cpp:259]     Train net output #0: loss = 0.450449 (* 1 = 0.450449 loss)
I1023 23:32:26.969776 21451 solver.cpp:590] Iteration 9300, lr = 0.001
I1023 23:32:39.403417 21451 solver.cpp:243] Iteration 9400, loss = 0.465971
I1023 23:32:39.403483 21451 solver.cpp:259]     Train net output #0: loss = 0.465971 (* 1 = 0.465971 loss)
I1023 23:32:39.403493 21451 solver.cpp:590] Iteration 9400, lr = 0.001
I1023 23:32:51.934345 21451 solver.cpp:243] Iteration 9500, loss = 0.540559
I1023 23:32:51.934376 21451 solver.cpp:259]     Train net output #0: loss = 0.540559 (* 1 = 0.540559 loss)
I1023 23:32:51.934386 21451 solver.cpp:590] Iteration 9500, lr = 0.001
I1023 23:33:04.223211 21451 solver.cpp:243] Iteration 9600, loss = 0.278737
I1023 23:33:04.223242 21451 solver.cpp:259]     Train net output #0: loss = 0.278737 (* 1 = 0.278737 loss)
I1023 23:33:04.223250 21451 solver.cpp:590] Iteration 9600, lr = 0.001
I1023 23:33:16.559520 21451 solver.cpp:243] Iteration 9700, loss = 0.474575
I1023 23:33:16.559602 21451 solver.cpp:259]     Train net output #0: loss = 0.474575 (* 1 = 0.474575 loss)
I1023 23:33:16.559612 21451 solver.cpp:590] Iteration 9700, lr = 0.001
I1023 23:33:28.664832 21451 solver.cpp:243] Iteration 9800, loss = 0.429568
I1023 23:33:28.664870 21451 solver.cpp:259]     Train net output #0: loss = 0.429568 (* 1 = 0.429568 loss)
I1023 23:33:28.664877 21451 solver.cpp:590] Iteration 9800, lr = 0.001
I1023 23:33:41.474632 21451 solver.cpp:243] Iteration 9900, loss = 0.56832
I1023 23:33:41.474663 21451 solver.cpp:259]     Train net output #0: loss = 0.56832 (* 1 = 0.56832 loss)
I1023 23:33:41.474673 21451 solver.cpp:590] Iteration 9900, lr = 0.001
I1023 23:33:53.401368 21451 solver.cpp:468] Snapshotting to binary proto file examples/nuclei/multi_class_nuclei/multi_class_nuclei_1_iter_10000.caffemodel
I1023 23:33:53.509137 21451 solver.cpp:753] Snapshotting solver state to binary proto file examples/nuclei/multi_class_nuclei/multi_class_nuclei_1_iter_10000.solverstate
I1023 23:33:53.510022 21451 solver.cpp:347] Iteration 10000, Testing net (#0)
I1023 23:34:08.242045 21451 solver.cpp:415]     Test net output #0: accuracy = 0.861772
I1023 23:34:08.242081 21451 solver.cpp:415]     Test net output #1: loss = 0.390954 (* 1 = 0.390954 loss)
I1023 23:34:08.298449 21451 solver.cpp:243] Iteration 10000, loss = 0.30585
I1023 23:34:08.298481 21451 solver.cpp:259]     Train net output #0: loss = 0.30585 (* 1 = 0.30585 loss)
I1023 23:34:08.298491 21451 solver.cpp:590] Iteration 10000, lr = 0.001
I1023 23:34:20.120049 21451 solver.cpp:243] Iteration 10100, loss = 0.380066
I1023 23:34:20.120084 21451 solver.cpp:259]     Train net output #0: loss = 0.380066 (* 1 = 0.380066 loss)
I1023 23:34:20.120091 21451 solver.cpp:590] Iteration 10100, lr = 0.001
I1023 23:34:31.945863 21451 solver.cpp:243] Iteration 10200, loss = 0.524687
I1023 23:34:31.945945 21451 solver.cpp:259]     Train net output #0: loss = 0.524686 (* 1 = 0.524686 loss)
I1023 23:34:31.945955 21451 solver.cpp:590] Iteration 10200, lr = 0.001
I1023 23:34:43.773764 21451 solver.cpp:243] Iteration 10300, loss = 0.419007
I1023 23:34:43.773800 21451 solver.cpp:259]     Train net output #0: loss = 0.419007 (* 1 = 0.419007 loss)
I1023 23:34:43.773808 21451 solver.cpp:590] Iteration 10300, lr = 0.001
I1023 23:34:55.609736 21451 solver.cpp:243] Iteration 10400, loss = 0.499389
I1023 23:34:55.609771 21451 solver.cpp:259]     Train net output #0: loss = 0.499389 (* 1 = 0.499389 loss)
I1023 23:34:55.609779 21451 solver.cpp:590] Iteration 10400, lr = 0.001
I1023 23:35:07.438899 21451 solver.cpp:243] Iteration 10500, loss = 0.368714
I1023 23:35:07.438982 21451 solver.cpp:259]     Train net output #0: loss = 0.368714 (* 1 = 0.368714 loss)
I1023 23:35:07.438997 21451 solver.cpp:590] Iteration 10500, lr = 0.001
I1023 23:35:19.366597 21451 solver.cpp:243] Iteration 10600, loss = 0.264773
I1023 23:35:19.366631 21451 solver.cpp:259]     Train net output #0: loss = 0.264773 (* 1 = 0.264773 loss)
I1023 23:35:19.366641 21451 solver.cpp:590] Iteration 10600, lr = 0.001
I1023 23:35:31.432729 21451 solver.cpp:243] Iteration 10700, loss = 0.489031
I1023 23:35:31.432759 21451 solver.cpp:259]     Train net output #0: loss = 0.489031 (* 1 = 0.489031 loss)
I1023 23:35:31.432768 21451 solver.cpp:590] Iteration 10700, lr = 0.001
I1023 23:35:43.383708 21451 solver.cpp:243] Iteration 10800, loss = 0.42082
I1023 23:35:43.383774 21451 solver.cpp:259]     Train net output #0: loss = 0.42082 (* 1 = 0.42082 loss)
I1023 23:35:43.383785 21451 solver.cpp:590] Iteration 10800, lr = 0.001
I1023 23:35:55.208681 21451 solver.cpp:243] Iteration 10900, loss = 0.312141
I1023 23:35:55.208712 21451 solver.cpp:259]     Train net output #0: loss = 0.312141 (* 1 = 0.312141 loss)
I1023 23:35:55.208720 21451 solver.cpp:590] Iteration 10900, lr = 0.001
I1023 23:36:06.918349 21451 solver.cpp:347] Iteration 11000, Testing net (#0)
I1023 23:36:21.411810 21451 solver.cpp:415]     Test net output #0: accuracy = 0.843086
I1023 23:36:21.411885 21451 solver.cpp:415]     Test net output #1: loss = 0.430556 (* 1 = 0.430556 loss)
I1023 23:36:21.474843 21451 solver.cpp:243] Iteration 11000, loss = 0.29727
I1023 23:36:21.474884 21451 solver.cpp:259]     Train net output #0: loss = 0.29727 (* 1 = 0.29727 loss)
I1023 23:36:21.474897 21451 solver.cpp:590] Iteration 11000, lr = 0.001
I1023 23:36:33.585716 21451 solver.cpp:243] Iteration 11100, loss = 0.329407
I1023 23:36:33.585747 21451 solver.cpp:259]     Train net output #0: loss = 0.329407 (* 1 = 0.329407 loss)
I1023 23:36:33.585759 21451 solver.cpp:590] Iteration 11100, lr = 0.001
I1023 23:36:45.478533 21451 solver.cpp:243] Iteration 11200, loss = 0.237223
I1023 23:36:45.478564 21451 solver.cpp:259]     Train net output #0: loss = 0.237223 (* 1 = 0.237223 loss)
I1023 23:36:45.478571 21451 solver.cpp:590] Iteration 11200, lr = 0.001
I1023 23:36:57.460865 21451 solver.cpp:243] Iteration 11300, loss = 0.310553
I1023 23:36:57.460935 21451 solver.cpp:259]     Train net output #0: loss = 0.310553 (* 1 = 0.310553 loss)
I1023 23:36:57.460945 21451 solver.cpp:590] Iteration 11300, lr = 0.001
I1023 23:37:09.852903 21451 solver.cpp:243] Iteration 11400, loss = 0.311708
I1023 23:37:09.852936 21451 solver.cpp:259]     Train net output #0: loss = 0.311708 (* 1 = 0.311708 loss)
I1023 23:37:09.852946 21451 solver.cpp:590] Iteration 11400, lr = 0.001
I1023 23:37:21.923319 21451 solver.cpp:243] Iteration 11500, loss = 0.313154
I1023 23:37:21.923353 21451 solver.cpp:259]     Train net output #0: loss = 0.313154 (* 1 = 0.313154 loss)
I1023 23:37:21.923362 21451 solver.cpp:590] Iteration 11500, lr = 0.001
I1023 23:37:33.858116 21451 solver.cpp:243] Iteration 11600, loss = 0.461672
I1023 23:37:33.858185 21451 solver.cpp:259]     Train net output #0: loss = 0.461672 (* 1 = 0.461672 loss)
I1023 23:37:33.858193 21451 solver.cpp:590] Iteration 11600, lr = 0.001
I1023 23:37:45.714707 21451 solver.cpp:243] Iteration 11700, loss = 0.384656
I1023 23:37:45.714740 21451 solver.cpp:259]     Train net output #0: loss = 0.384656 (* 1 = 0.384656 loss)
I1023 23:37:45.714747 21451 solver.cpp:590] Iteration 11700, lr = 0.001
I1023 23:37:57.538343 21451 solver.cpp:243] Iteration 11800, loss = 0.270071
I1023 23:37:57.538375 21451 solver.cpp:259]     Train net output #0: loss = 0.27007 (* 1 = 0.27007 loss)
I1023 23:37:57.538383 21451 solver.cpp:590] Iteration 11800, lr = 0.001
I1023 23:38:09.376989 21451 solver.cpp:243] Iteration 11900, loss = 0.312379
I1023 23:38:09.377084 21451 solver.cpp:259]     Train net output #0: loss = 0.312379 (* 1 = 0.312379 loss)
I1023 23:38:09.377097 21451 solver.cpp:590] Iteration 11900, lr = 0.001
I1023 23:38:21.084693 21451 solver.cpp:347] Iteration 12000, Testing net (#0)
I1023 23:38:35.570451 21451 solver.cpp:415]     Test net output #0: accuracy = 0.865572
I1023 23:38:35.570489 21451 solver.cpp:415]     Test net output #1: loss = 0.387093 (* 1 = 0.387093 loss)
I1023 23:38:35.627826 21451 solver.cpp:243] Iteration 12000, loss = 0.383079
I1023 23:38:35.627866 21451 solver.cpp:259]     Train net output #0: loss = 0.383078 (* 1 = 0.383078 loss)
I1023 23:38:35.627878 21451 solver.cpp:590] Iteration 12000, lr = 0.001
I1023 23:38:47.452227 21451 solver.cpp:243] Iteration 12100, loss = 0.262317
I1023 23:38:47.452280 21451 solver.cpp:259]     Train net output #0: loss = 0.262316 (* 1 = 0.262316 loss)
I1023 23:38:47.452288 21451 solver.cpp:590] Iteration 12100, lr = 0.001
I1023 23:38:59.275152 21451 solver.cpp:243] Iteration 12200, loss = 0.483003
I1023 23:38:59.275182 21451 solver.cpp:259]     Train net output #0: loss = 0.483002 (* 1 = 0.483002 loss)
I1023 23:38:59.275193 21451 solver.cpp:590] Iteration 12200, lr = 0.001
I1023 23:39:11.104557 21451 solver.cpp:243] Iteration 12300, loss = 0.339619
I1023 23:39:11.104588 21451 solver.cpp:259]     Train net output #0: loss = 0.339619 (* 1 = 0.339619 loss)
I1023 23:39:11.104595 21451 solver.cpp:590] Iteration 12300, lr = 0.001
I1023 23:39:24.673470 21451 solver.cpp:243] Iteration 12400, loss = 0.541863
I1023 23:39:24.673526 21451 solver.cpp:259]     Train net output #0: loss = 0.541862 (* 1 = 0.541862 loss)
I1023 23:39:24.673534 21451 solver.cpp:590] Iteration 12400, lr = 0.001
I1023 23:39:38.636355 21451 solver.cpp:243] Iteration 12500, loss = 0.334019
I1023 23:39:38.636422 21451 solver.cpp:259]     Train net output #0: loss = 0.334019 (* 1 = 0.334019 loss)
I1023 23:39:38.636438 21451 solver.cpp:590] Iteration 12500, lr = 0.001
I1023 23:39:52.207257 21451 solver.cpp:243] Iteration 12600, loss = 0.211296
I1023 23:39:52.207290 21451 solver.cpp:259]     Train net output #0: loss = 0.211295 (* 1 = 0.211295 loss)
I1023 23:39:52.207298 21451 solver.cpp:590] Iteration 12600, lr = 0.001
I1023 23:40:04.072788 21451 solver.cpp:243] Iteration 12700, loss = 0.458972
I1023 23:40:04.072913 21451 solver.cpp:259]     Train net output #0: loss = 0.458972 (* 1 = 0.458972 loss)
I1023 23:40:04.072932 21451 solver.cpp:590] Iteration 12700, lr = 0.001
I1023 23:40:16.456555 21451 solver.cpp:243] Iteration 12800, loss = 0.303836
I1023 23:40:16.456586 21451 solver.cpp:259]     Train net output #0: loss = 0.303836 (* 1 = 0.303836 loss)
I1023 23:40:16.456593 21451 solver.cpp:590] Iteration 12800, lr = 0.001
I1023 23:40:28.731057 21451 solver.cpp:243] Iteration 12900, loss = 0.37334
I1023 23:40:28.731089 21451 solver.cpp:259]     Train net output #0: loss = 0.37334 (* 1 = 0.37334 loss)
I1023 23:40:28.731098 21451 solver.cpp:590] Iteration 12900, lr = 0.001
I1023 23:40:41.572648 21451 solver.cpp:347] Iteration 13000, Testing net (#0)
I1023 23:40:56.694478 21451 solver.cpp:415]     Test net output #0: accuracy = 0.827457
I1023 23:40:56.694510 21451 solver.cpp:415]     Test net output #1: loss = 0.446636 (* 1 = 0.446636 loss)
I1023 23:40:56.752764 21451 solver.cpp:243] Iteration 13000, loss = 0.466041
I1023 23:40:56.752797 21451 solver.cpp:259]     Train net output #0: loss = 0.466041 (* 1 = 0.466041 loss)
I1023 23:40:56.752805 21451 solver.cpp:590] Iteration 13000, lr = 0.001
I1023 23:41:09.151124 21451 solver.cpp:243] Iteration 13100, loss = 0.348918
I1023 23:41:09.151168 21451 solver.cpp:259]     Train net output #0: loss = 0.348917 (* 1 = 0.348917 loss)
I1023 23:41:09.151182 21451 solver.cpp:590] Iteration 13100, lr = 0.001
I1023 23:41:21.657565 21451 solver.cpp:243] Iteration 13200, loss = 0.332985
I1023 23:41:21.657654 21451 solver.cpp:259]     Train net output #0: loss = 0.332984 (* 1 = 0.332984 loss)
I1023 23:41:21.657667 21451 solver.cpp:590] Iteration 13200, lr = 0.001
I1023 23:41:33.563732 21451 solver.cpp:243] Iteration 13300, loss = 0.339425
I1023 23:41:33.563767 21451 solver.cpp:259]     Train net output #0: loss = 0.339425 (* 1 = 0.339425 loss)
I1023 23:41:33.563779 21451 solver.cpp:590] Iteration 13300, lr = 0.001
I1023 23:41:46.784085 21451 solver.cpp:243] Iteration 13400, loss = 0.352744
I1023 23:41:46.784119 21451 solver.cpp:259]     Train net output #0: loss = 0.352744 (* 1 = 0.352744 loss)
I1023 23:41:46.784132 21451 solver.cpp:590] Iteration 13400, lr = 0.001
I1023 23:42:00.445173 21451 solver.cpp:243] Iteration 13500, loss = 0.531483
I1023 23:42:00.445262 21451 solver.cpp:259]     Train net output #0: loss = 0.531483 (* 1 = 0.531483 loss)
I1023 23:42:00.445272 21451 solver.cpp:590] Iteration 13500, lr = 0.001
I1023 23:42:13.032855 21451 solver.cpp:243] Iteration 13600, loss = 0.359159
I1023 23:42:13.032887 21451 solver.cpp:259]     Train net output #0: loss = 0.359159 (* 1 = 0.359159 loss)
I1023 23:42:13.032896 21451 solver.cpp:590] Iteration 13600, lr = 0.001
I1023 23:42:25.967695 21451 solver.cpp:243] Iteration 13700, loss = 0.533139
I1023 23:42:25.967737 21451 solver.cpp:259]     Train net output #0: loss = 0.533139 (* 1 = 0.533139 loss)
I1023 23:42:25.967751 21451 solver.cpp:590] Iteration 13700, lr = 0.001
I1023 23:42:39.104315 21451 solver.cpp:243] Iteration 13800, loss = 0.309421
I1023 23:42:39.104365 21451 solver.cpp:259]     Train net output #0: loss = 0.30942 (* 1 = 0.30942 loss)
I1023 23:42:39.104377 21451 solver.cpp:590] Iteration 13800, lr = 0.001
I1023 23:42:51.359542 21451 solver.cpp:243] Iteration 13900, loss = 0.48331
I1023 23:42:51.359580 21451 solver.cpp:259]     Train net output #0: loss = 0.48331 (* 1 = 0.48331 loss)
I1023 23:42:51.359591 21451 solver.cpp:590] Iteration 13900, lr = 0.001
I1023 23:43:04.325531 21451 solver.cpp:347] Iteration 14000, Testing net (#0)
I1023 23:43:18.855877 21451 solver.cpp:415]     Test net output #0: accuracy = 0.845114
I1023 23:43:18.855928 21451 solver.cpp:415]     Test net output #1: loss = 0.43584 (* 1 = 0.43584 loss)
I1023 23:43:18.913192 21451 solver.cpp:243] Iteration 14000, loss = 0.33592
I1023 23:43:18.913228 21451 solver.cpp:259]     Train net output #0: loss = 0.33592 (* 1 = 0.33592 loss)
I1023 23:43:18.913238 21451 solver.cpp:590] Iteration 14000, lr = 0.001
I1023 23:43:30.847105 21451 solver.cpp:243] Iteration 14100, loss = 0.271979
I1023 23:43:30.847134 21451 solver.cpp:259]     Train net output #0: loss = 0.271979 (* 1 = 0.271979 loss)
I1023 23:43:30.847142 21451 solver.cpp:590] Iteration 14100, lr = 0.001
I1023 23:43:42.736747 21451 solver.cpp:243] Iteration 14200, loss = 0.346046
I1023 23:43:42.736784 21451 solver.cpp:259]     Train net output #0: loss = 0.346046 (* 1 = 0.346046 loss)
I1023 23:43:42.736793 21451 solver.cpp:590] Iteration 14200, lr = 0.001
I1023 23:43:54.618031 21451 solver.cpp:243] Iteration 14300, loss = 0.445096
I1023 23:43:54.618103 21451 solver.cpp:259]     Train net output #0: loss = 0.445095 (* 1 = 0.445095 loss)
I1023 23:43:54.618113 21451 solver.cpp:590] Iteration 14300, lr = 0.001
I1023 23:44:06.519253 21451 solver.cpp:243] Iteration 14400, loss = 0.29213
I1023 23:44:06.519286 21451 solver.cpp:259]     Train net output #0: loss = 0.29213 (* 1 = 0.29213 loss)
I1023 23:44:06.519294 21451 solver.cpp:590] Iteration 14400, lr = 0.001
I1023 23:44:18.396158 21451 solver.cpp:243] Iteration 14500, loss = 0.33184
I1023 23:44:18.396188 21451 solver.cpp:259]     Train net output #0: loss = 0.33184 (* 1 = 0.33184 loss)
I1023 23:44:18.396196 21451 solver.cpp:590] Iteration 14500, lr = 0.001
I1023 23:44:30.276136 21451 solver.cpp:243] Iteration 14600, loss = 0.270584
I1023 23:44:30.276202 21451 solver.cpp:259]     Train net output #0: loss = 0.270583 (* 1 = 0.270583 loss)
I1023 23:44:30.276211 21451 solver.cpp:590] Iteration 14600, lr = 0.001
I1023 23:44:42.385639 21451 solver.cpp:243] Iteration 14700, loss = 0.272616
I1023 23:44:42.385673 21451 solver.cpp:259]     Train net output #0: loss = 0.272615 (* 1 = 0.272615 loss)
I1023 23:44:42.385679 21451 solver.cpp:590] Iteration 14700, lr = 0.001
I1023 23:44:54.482118 21451 solver.cpp:243] Iteration 14800, loss = 0.373497
I1023 23:44:54.482151 21451 solver.cpp:259]     Train net output #0: loss = 0.373497 (* 1 = 0.373497 loss)
I1023 23:44:54.482159 21451 solver.cpp:590] Iteration 14800, lr = 0.001
I1023 23:45:06.384691 21451 solver.cpp:243] Iteration 14900, loss = 0.331932
I1023 23:45:06.384788 21451 solver.cpp:259]     Train net output #0: loss = 0.331932 (* 1 = 0.331932 loss)
I1023 23:45:06.384796 21451 solver.cpp:590] Iteration 14900, lr = 0.001
I1023 23:45:18.155992 21451 solver.cpp:347] Iteration 15000, Testing net (#0)
I1023 23:45:32.708230 21451 solver.cpp:415]     Test net output #0: accuracy = 0.862171
I1023 23:45:32.708262 21451 solver.cpp:415]     Test net output #1: loss = 0.369898 (* 1 = 0.369898 loss)
I1023 23:45:32.765805 21451 solver.cpp:243] Iteration 15000, loss = 0.290184
I1023 23:45:32.765838 21451 solver.cpp:259]     Train net output #0: loss = 0.290184 (* 1 = 0.290184 loss)
I1023 23:45:32.765846 21451 solver.cpp:590] Iteration 15000, lr = 0.001
