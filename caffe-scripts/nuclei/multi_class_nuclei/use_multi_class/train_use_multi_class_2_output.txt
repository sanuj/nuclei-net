I1030 12:37:30.887789  3774 caffe.cpp:184] Using GPUs 0
I1030 12:37:32.078667  3774 solver.cpp:54] Initializing solver from parameters: 
test_iter: 700
test_interval: 6665
base_lr: 0.001
display: 100
max_iter: 333250
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 166625
snapshot: 66650
snapshot_prefix: "examples/nuclei/multi_class_nuclei/use_multi_class/use_multi_class_nuclei_big_1"
solver_mode: GPU
device_id: 0
net: "examples/nuclei/multi_class_nuclei/use_multi_class/use_multi_class_test_train.prototxt"
I1030 12:37:32.078819  3774 solver.cpp:97] Creating training net from net file: examples/nuclei/multi_class_nuclei/use_multi_class/use_multi_class_test_train.prototxt
I1030 12:37:32.126435  3774 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer nuclei
I1030 12:37:32.126489  3774 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1030 12:37:32.126631  3774 net.cpp:50] Initializing net from parameters: 
name: "NULCEI_quick"
state {
  phase: TRAIN
}
layer {
  name: "nuclei"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  image_data_param {
    source: "/home/sanuj/temp_63_LLM_YR4_33/train_big.txt"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 6
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1030 12:37:32.126735  3774 layer_factory.hpp:76] Creating layer nuclei
I1030 12:37:32.143192  3774 net.cpp:110] Creating Layer nuclei
I1030 12:37:32.143226  3774 net.cpp:433] nuclei -> data
I1030 12:37:32.143261  3774 net.cpp:433] nuclei -> label
I1030 12:37:32.143280  3774 image_data_layer.cpp:37] Opening file /home/sanuj/temp_63_LLM_YR4_33/train_big.txt
I1030 12:37:33.108028  3774 image_data_layer.cpp:52] A total of 666540 images.
I1030 12:37:33.296844  3774 image_data_layer.cpp:79] output data size: 100,3,33,33
I1030 12:37:33.303377  3774 net.cpp:155] Setting up nuclei
I1030 12:37:33.303416  3774 net.cpp:163] Top shape: 100 3 33 33 (326700)
I1030 12:37:33.303429  3774 net.cpp:163] Top shape: 100 (100)
I1030 12:37:33.303441  3774 layer_factory.hpp:76] Creating layer conv1
I1030 12:37:33.303844  3774 net.cpp:110] Creating Layer conv1
I1030 12:37:33.303861  3774 net.cpp:477] conv1 <- data
I1030 12:37:33.303880  3774 net.cpp:433] conv1 -> conv1
I1030 12:37:33.315052  3774 net.cpp:155] Setting up conv1
I1030 12:37:33.315120  3774 net.cpp:163] Top shape: 100 48 30 30 (4320000)
I1030 12:37:33.315151  3774 layer_factory.hpp:76] Creating layer pool1
I1030 12:37:33.315181  3774 net.cpp:110] Creating Layer pool1
I1030 12:37:33.315189  3774 net.cpp:477] pool1 <- conv1
I1030 12:37:33.315198  3774 net.cpp:433] pool1 -> pool1
I1030 12:37:33.315251  3774 net.cpp:155] Setting up pool1
I1030 12:37:33.315259  3774 net.cpp:163] Top shape: 100 48 15 15 (1080000)
I1030 12:37:33.315263  3774 layer_factory.hpp:76] Creating layer relu1
I1030 12:37:33.315268  3774 net.cpp:110] Creating Layer relu1
I1030 12:37:33.315271  3774 net.cpp:477] relu1 <- pool1
I1030 12:37:33.315276  3774 net.cpp:419] relu1 -> pool1 (in-place)
I1030 12:37:33.315285  3774 net.cpp:155] Setting up relu1
I1030 12:37:33.315294  3774 net.cpp:163] Top shape: 100 48 15 15 (1080000)
I1030 12:37:33.315302  3774 layer_factory.hpp:76] Creating layer conv2
I1030 12:37:33.315320  3774 net.cpp:110] Creating Layer conv2
I1030 12:37:33.315327  3774 net.cpp:477] conv2 <- pool1
I1030 12:37:33.315337  3774 net.cpp:433] conv2 -> conv2
I1030 12:37:33.317986  3774 net.cpp:155] Setting up conv2
I1030 12:37:33.318008  3774 net.cpp:163] Top shape: 100 48 10 10 (480000)
I1030 12:37:33.318017  3774 layer_factory.hpp:76] Creating layer relu2
I1030 12:37:33.318024  3774 net.cpp:110] Creating Layer relu2
I1030 12:37:33.318029  3774 net.cpp:477] relu2 <- conv2
I1030 12:37:33.318034  3774 net.cpp:419] relu2 -> conv2 (in-place)
I1030 12:37:33.318040  3774 net.cpp:155] Setting up relu2
I1030 12:37:33.318049  3774 net.cpp:163] Top shape: 100 48 10 10 (480000)
I1030 12:37:33.318055  3774 layer_factory.hpp:76] Creating layer pool2
I1030 12:37:33.318066  3774 net.cpp:110] Creating Layer pool2
I1030 12:37:33.318084  3774 net.cpp:477] pool2 <- conv2
I1030 12:37:33.318100  3774 net.cpp:433] pool2 -> pool2
I1030 12:37:33.318135  3774 net.cpp:155] Setting up pool2
I1030 12:37:33.318142  3774 net.cpp:163] Top shape: 100 48 5 5 (120000)
I1030 12:37:33.318145  3774 layer_factory.hpp:76] Creating layer ip1
I1030 12:37:33.318152  3774 net.cpp:110] Creating Layer ip1
I1030 12:37:33.318157  3774 net.cpp:477] ip1 <- pool2
I1030 12:37:33.318166  3774 net.cpp:433] ip1 -> ip1
I1030 12:37:33.320018  3774 net.cpp:155] Setting up ip1
I1030 12:37:33.320035  3774 net.cpp:163] Top shape: 100 48 (4800)
I1030 12:37:33.320050  3774 layer_factory.hpp:76] Creating layer relu1
I1030 12:37:33.320063  3774 net.cpp:110] Creating Layer relu1
I1030 12:37:33.320075  3774 net.cpp:477] relu1 <- ip1
I1030 12:37:33.320104  3774 net.cpp:419] relu1 -> ip1 (in-place)
I1030 12:37:33.320114  3774 net.cpp:155] Setting up relu1
I1030 12:37:33.320119  3774 net.cpp:163] Top shape: 100 48 (4800)
I1030 12:37:33.320122  3774 layer_factory.hpp:76] Creating layer ip2
I1030 12:37:33.320130  3774 net.cpp:110] Creating Layer ip2
I1030 12:37:33.320134  3774 net.cpp:477] ip2 <- ip1
I1030 12:37:33.320139  3774 net.cpp:433] ip2 -> ip2
I1030 12:37:33.320220  3774 net.cpp:155] Setting up ip2
I1030 12:37:33.320226  3774 net.cpp:163] Top shape: 100 2 (200)
I1030 12:37:33.320232  3774 layer_factory.hpp:76] Creating layer loss
I1030 12:37:33.320240  3774 net.cpp:110] Creating Layer loss
I1030 12:37:33.320246  3774 net.cpp:477] loss <- ip2
I1030 12:37:33.320253  3774 net.cpp:477] loss <- label
I1030 12:37:33.320264  3774 net.cpp:433] loss -> loss
I1030 12:37:33.320276  3774 layer_factory.hpp:76] Creating layer loss
I1030 12:37:33.340771  3774 net.cpp:155] Setting up loss
I1030 12:37:33.340802  3774 net.cpp:163] Top shape: (1)
I1030 12:37:33.340807  3774 net.cpp:168]     with loss weight 1
I1030 12:37:33.340826  3774 net.cpp:236] loss needs backward computation.
I1030 12:37:33.340832  3774 net.cpp:236] ip2 needs backward computation.
I1030 12:37:33.340839  3774 net.cpp:236] relu1 needs backward computation.
I1030 12:37:33.340845  3774 net.cpp:236] ip1 needs backward computation.
I1030 12:37:33.340852  3774 net.cpp:236] pool2 needs backward computation.
I1030 12:37:33.340891  3774 net.cpp:236] relu2 needs backward computation.
I1030 12:37:33.340915  3774 net.cpp:236] conv2 needs backward computation.
I1030 12:37:33.340924  3774 net.cpp:236] relu1 needs backward computation.
I1030 12:37:33.340931  3774 net.cpp:236] pool1 needs backward computation.
I1030 12:37:33.340939  3774 net.cpp:236] conv1 needs backward computation.
I1030 12:37:33.340946  3774 net.cpp:240] nuclei does not need backward computation.
I1030 12:37:33.340956  3774 net.cpp:283] This network produces output loss
I1030 12:37:33.340975  3774 net.cpp:297] Network initialization done.
I1030 12:37:33.340978  3774 net.cpp:298] Memory required for data: 31586404
I1030 12:37:33.341316  3774 solver.cpp:187] Creating test net (#0) specified by net file: examples/nuclei/multi_class_nuclei/use_multi_class/use_multi_class_test_train.prototxt
I1030 12:37:33.341346  3774 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer nuclei
I1030 12:37:33.341444  3774 net.cpp:50] Initializing net from parameters: 
name: "NULCEI_quick"
state {
  phase: TEST
}
layer {
  name: "nuclei"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  image_data_param {
    source: "/home/sanuj/temp_63_LLM_YR4_33/test_big.txt"
    batch_size: 500
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.2
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 6
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1030 12:37:33.341516  3774 layer_factory.hpp:76] Creating layer nuclei
I1030 12:37:33.341531  3774 net.cpp:110] Creating Layer nuclei
I1030 12:37:33.341541  3774 net.cpp:433] nuclei -> data
I1030 12:37:33.341552  3774 net.cpp:433] nuclei -> label
I1030 12:37:33.341562  3774 image_data_layer.cpp:37] Opening file /home/sanuj/temp_63_LLM_YR4_33/test_big.txt
I1030 12:37:34.235007  3774 image_data_layer.cpp:52] A total of 350019 images.
I1030 12:37:34.269681  3774 image_data_layer.cpp:79] output data size: 500,3,33,33
I1030 12:37:34.302474  3774 net.cpp:155] Setting up nuclei
I1030 12:37:34.302513  3774 net.cpp:163] Top shape: 500 3 33 33 (1633500)
I1030 12:37:34.302523  3774 net.cpp:163] Top shape: 500 (500)
I1030 12:37:34.302533  3774 layer_factory.hpp:76] Creating layer label_nuclei_1_split
I1030 12:37:34.302552  3774 net.cpp:110] Creating Layer label_nuclei_1_split
I1030 12:37:34.302600  3774 net.cpp:477] label_nuclei_1_split <- label
I1030 12:37:34.302631  3774 net.cpp:433] label_nuclei_1_split -> label_nuclei_1_split_0
I1030 12:37:34.302660  3774 net.cpp:433] label_nuclei_1_split -> label_nuclei_1_split_1
I1030 12:37:34.302732  3774 net.cpp:155] Setting up label_nuclei_1_split
I1030 12:37:34.302747  3774 net.cpp:163] Top shape: 500 (500)
I1030 12:37:34.302755  3774 net.cpp:163] Top shape: 500 (500)
I1030 12:37:34.302778  3774 layer_factory.hpp:76] Creating layer conv1
I1030 12:37:34.302809  3774 net.cpp:110] Creating Layer conv1
I1030 12:37:34.302832  3774 net.cpp:477] conv1 <- data
I1030 12:37:34.302860  3774 net.cpp:433] conv1 -> conv1
I1030 12:37:34.303115  3774 net.cpp:155] Setting up conv1
I1030 12:37:34.303128  3774 net.cpp:163] Top shape: 500 48 30 30 (21600000)
I1030 12:37:34.303143  3774 layer_factory.hpp:76] Creating layer pool1
I1030 12:37:34.303158  3774 net.cpp:110] Creating Layer pool1
I1030 12:37:34.303165  3774 net.cpp:477] pool1 <- conv1
I1030 12:37:34.303174  3774 net.cpp:433] pool1 -> pool1
I1030 12:37:34.303215  3774 net.cpp:155] Setting up pool1
I1030 12:37:34.303223  3774 net.cpp:163] Top shape: 500 48 15 15 (5400000)
I1030 12:37:34.303230  3774 layer_factory.hpp:76] Creating layer relu1
I1030 12:37:34.303254  3774 net.cpp:110] Creating Layer relu1
I1030 12:37:34.303261  3774 net.cpp:477] relu1 <- pool1
I1030 12:37:34.303268  3774 net.cpp:419] relu1 -> pool1 (in-place)
I1030 12:37:34.303279  3774 net.cpp:155] Setting up relu1
I1030 12:37:34.303289  3774 net.cpp:163] Top shape: 500 48 15 15 (5400000)
I1030 12:37:34.303297  3774 layer_factory.hpp:76] Creating layer conv2
I1030 12:37:34.303319  3774 net.cpp:110] Creating Layer conv2
I1030 12:37:34.303325  3774 net.cpp:477] conv2 <- pool1
I1030 12:37:34.303334  3774 net.cpp:433] conv2 -> conv2
I1030 12:37:34.311086  3774 net.cpp:155] Setting up conv2
I1030 12:37:34.311110  3774 net.cpp:163] Top shape: 500 48 10 10 (2400000)
I1030 12:37:34.311130  3774 layer_factory.hpp:76] Creating layer relu2
I1030 12:37:34.311144  3774 net.cpp:110] Creating Layer relu2
I1030 12:37:34.311170  3774 net.cpp:477] relu2 <- conv2
I1030 12:37:34.311182  3774 net.cpp:419] relu2 -> conv2 (in-place)
I1030 12:37:34.311205  3774 net.cpp:155] Setting up relu2
I1030 12:37:34.311214  3774 net.cpp:163] Top shape: 500 48 10 10 (2400000)
I1030 12:37:34.311223  3774 layer_factory.hpp:76] Creating layer pool2
I1030 12:37:34.311242  3774 net.cpp:110] Creating Layer pool2
I1030 12:37:34.311249  3774 net.cpp:477] pool2 <- conv2
I1030 12:37:34.311257  3774 net.cpp:433] pool2 -> pool2
I1030 12:37:34.311308  3774 net.cpp:155] Setting up pool2
I1030 12:37:34.311317  3774 net.cpp:163] Top shape: 500 48 5 5 (600000)
I1030 12:37:34.311324  3774 layer_factory.hpp:76] Creating layer ip1
I1030 12:37:34.311336  3774 net.cpp:110] Creating Layer ip1
I1030 12:37:34.311343  3774 net.cpp:477] ip1 <- pool2
I1030 12:37:34.311354  3774 net.cpp:433] ip1 -> ip1
I1030 12:37:34.312844  3774 net.cpp:155] Setting up ip1
I1030 12:37:34.312858  3774 net.cpp:163] Top shape: 500 48 (24000)
I1030 12:37:34.312872  3774 layer_factory.hpp:76] Creating layer relu1
I1030 12:37:34.312897  3774 net.cpp:110] Creating Layer relu1
I1030 12:37:34.312903  3774 net.cpp:477] relu1 <- ip1
I1030 12:37:34.312913  3774 net.cpp:419] relu1 -> ip1 (in-place)
I1030 12:37:34.312924  3774 net.cpp:155] Setting up relu1
I1030 12:37:34.312929  3774 net.cpp:163] Top shape: 500 48 (24000)
I1030 12:37:34.312933  3774 layer_factory.hpp:76] Creating layer ip2
I1030 12:37:34.312940  3774 net.cpp:110] Creating Layer ip2
I1030 12:37:34.312944  3774 net.cpp:477] ip2 <- ip1
I1030 12:37:34.312948  3774 net.cpp:433] ip2 -> ip2
I1030 12:37:34.313031  3774 net.cpp:155] Setting up ip2
I1030 12:37:34.313038  3774 net.cpp:163] Top shape: 500 2 (1000)
I1030 12:37:34.313045  3774 layer_factory.hpp:76] Creating layer ip2_ip2_0_split
I1030 12:37:34.313050  3774 net.cpp:110] Creating Layer ip2_ip2_0_split
I1030 12:37:34.313055  3774 net.cpp:477] ip2_ip2_0_split <- ip2
I1030 12:37:34.313058  3774 net.cpp:433] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1030 12:37:34.313076  3774 net.cpp:433] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1030 12:37:34.313105  3774 net.cpp:155] Setting up ip2_ip2_0_split
I1030 12:37:34.313112  3774 net.cpp:163] Top shape: 500 2 (1000)
I1030 12:37:34.313117  3774 net.cpp:163] Top shape: 500 2 (1000)
I1030 12:37:34.313119  3774 layer_factory.hpp:76] Creating layer accuracy
I1030 12:37:34.313124  3774 net.cpp:110] Creating Layer accuracy
I1030 12:37:34.313128  3774 net.cpp:477] accuracy <- ip2_ip2_0_split_0
I1030 12:37:34.313133  3774 net.cpp:477] accuracy <- label_nuclei_1_split_0
I1030 12:37:34.313138  3774 net.cpp:433] accuracy -> accuracy
I1030 12:37:34.313144  3774 net.cpp:155] Setting up accuracy
I1030 12:37:34.313149  3774 net.cpp:163] Top shape: (1)
I1030 12:37:34.313153  3774 layer_factory.hpp:76] Creating layer loss
I1030 12:37:34.313158  3774 net.cpp:110] Creating Layer loss
I1030 12:37:34.313161  3774 net.cpp:477] loss <- ip2_ip2_0_split_1
I1030 12:37:34.313165  3774 net.cpp:477] loss <- label_nuclei_1_split_1
I1030 12:37:34.313169  3774 net.cpp:433] loss -> loss
I1030 12:37:34.313175  3774 layer_factory.hpp:76] Creating layer loss
I1030 12:37:34.313254  3774 net.cpp:155] Setting up loss
I1030 12:37:34.313261  3774 net.cpp:163] Top shape: (1)
I1030 12:37:34.313264  3774 net.cpp:168]     with loss weight 1
I1030 12:37:34.313274  3774 net.cpp:236] loss needs backward computation.
I1030 12:37:34.313278  3774 net.cpp:240] accuracy does not need backward computation.
I1030 12:37:34.313282  3774 net.cpp:236] ip2_ip2_0_split needs backward computation.
I1030 12:37:34.313285  3774 net.cpp:236] ip2 needs backward computation.
I1030 12:37:34.313288  3774 net.cpp:236] relu1 needs backward computation.
I1030 12:37:34.313292  3774 net.cpp:236] ip1 needs backward computation.
I1030 12:37:34.313294  3774 net.cpp:236] pool2 needs backward computation.
I1030 12:37:34.313298  3774 net.cpp:236] relu2 needs backward computation.
I1030 12:37:34.313302  3774 net.cpp:236] conv2 needs backward computation.
I1030 12:37:34.313304  3774 net.cpp:236] relu1 needs backward computation.
I1030 12:37:34.313308  3774 net.cpp:236] pool1 needs backward computation.
I1030 12:37:34.313310  3774 net.cpp:236] conv1 needs backward computation.
I1030 12:37:34.313314  3774 net.cpp:240] label_nuclei_1_split does not need backward computation.
I1030 12:37:34.313318  3774 net.cpp:240] nuclei does not need backward computation.
I1030 12:37:34.313321  3774 net.cpp:283] This network produces output accuracy
I1030 12:37:34.313324  3774 net.cpp:283] This network produces output loss
I1030 12:37:34.313335  3774 net.cpp:297] Network initialization done.
I1030 12:37:34.313339  3774 net.cpp:298] Memory required for data: 157944008
I1030 12:37:34.313385  3774 solver.cpp:66] Solver scaffolding done.
I1030 12:37:34.313604  3774 caffe.cpp:202] Resuming from examples/nuclei/multi_class_nuclei/use_multi_class/use_multi_class_nuclei_big_1_iter_51647.solverstate
I1030 12:37:34.720824  3774 solver.cpp:798] SGDSolver: restoring history
I1030 12:37:34.721185  3774 caffe.cpp:212] Starting Optimization
I1030 12:37:34.721197  3774 solver.cpp:294] Solving NULCEI_quick
I1030 12:37:34.721202  3774 solver.cpp:295] Learning Rate Policy: step
I1030 12:37:34.764786  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 12:39:50.369935  3774 solver.cpp:243] Iteration 51700, loss = 0.0990742
I1030 12:39:50.370057  3774 solver.cpp:259]     Train net output #0: loss = 0.0990742 (* 1 = 0.0990742 loss)
I1030 12:39:50.370067  3774 solver.cpp:590] Iteration 51700, lr = 0.001
I1030 12:42:32.887236  3774 solver.cpp:243] Iteration 51800, loss = 0.157701
I1030 12:42:32.887315  3774 solver.cpp:259]     Train net output #0: loss = 0.157701 (* 1 = 0.157701 loss)
I1030 12:42:32.887329  3774 solver.cpp:590] Iteration 51800, lr = 0.001
I1030 12:44:59.838310  3774 solver.cpp:243] Iteration 51900, loss = 0.125695
I1030 12:44:59.838457  3774 solver.cpp:259]     Train net output #0: loss = 0.125695 (* 1 = 0.125695 loss)
I1030 12:44:59.838523  3774 solver.cpp:590] Iteration 51900, lr = 0.001
I1030 12:47:23.849226  3774 solver.cpp:243] Iteration 52000, loss = 0.165638
I1030 12:47:23.849314  3774 solver.cpp:259]     Train net output #0: loss = 0.165638 (* 1 = 0.165638 loss)
I1030 12:47:23.849324  3774 solver.cpp:590] Iteration 52000, lr = 0.001
I1030 12:49:41.822314  3774 solver.cpp:243] Iteration 52100, loss = 0.133
I1030 12:49:41.822391  3774 solver.cpp:259]     Train net output #0: loss = 0.133 (* 1 = 0.133 loss)
I1030 12:49:41.822404  3774 solver.cpp:590] Iteration 52100, lr = 0.001
I1030 12:51:53.807258  3774 solver.cpp:243] Iteration 52200, loss = 0.177038
I1030 12:51:53.807418  3774 solver.cpp:259]     Train net output #0: loss = 0.177038 (* 1 = 0.177038 loss)
I1030 12:51:53.807433  3774 solver.cpp:590] Iteration 52200, lr = 0.001
I1030 12:54:08.090293  3774 solver.cpp:243] Iteration 52300, loss = 0.135203
I1030 12:54:08.090394  3774 solver.cpp:259]     Train net output #0: loss = 0.135203 (* 1 = 0.135203 loss)
I1030 12:54:08.090421  3774 solver.cpp:590] Iteration 52300, lr = 0.001
I1030 12:56:20.911679  3774 solver.cpp:243] Iteration 52400, loss = 0.174065
I1030 12:56:20.911773  3774 solver.cpp:259]     Train net output #0: loss = 0.174065 (* 1 = 0.174065 loss)
I1030 12:56:20.911793  3774 solver.cpp:590] Iteration 52400, lr = 0.001
I1030 12:58:51.244801  3774 solver.cpp:243] Iteration 52500, loss = 0.162095
I1030 12:58:51.244933  3774 solver.cpp:259]     Train net output #0: loss = 0.162095 (* 1 = 0.162095 loss)
I1030 12:58:51.244946  3774 solver.cpp:590] Iteration 52500, lr = 0.001
I1030 13:01:02.653734  3774 solver.cpp:243] Iteration 52600, loss = 0.164317
I1030 13:01:02.653830  3774 solver.cpp:259]     Train net output #0: loss = 0.164317 (* 1 = 0.164317 loss)
I1030 13:01:02.653848  3774 solver.cpp:590] Iteration 52600, lr = 0.001
I1030 13:02:06.733816  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 13:03:22.549088  3774 solver.cpp:243] Iteration 52700, loss = 0.200045
I1030 13:03:22.549175  3774 solver.cpp:259]     Train net output #0: loss = 0.200045 (* 1 = 0.200045 loss)
I1030 13:03:22.549187  3774 solver.cpp:590] Iteration 52700, lr = 0.001
I1030 13:05:40.938482  3774 solver.cpp:243] Iteration 52800, loss = 0.0926372
I1030 13:05:40.938542  3774 solver.cpp:259]     Train net output #0: loss = 0.0926372 (* 1 = 0.0926372 loss)
I1030 13:05:40.938552  3774 solver.cpp:590] Iteration 52800, lr = 0.001
I1030 13:08:01.495590  3774 solver.cpp:243] Iteration 52900, loss = 0.145442
I1030 13:08:01.495785  3774 solver.cpp:259]     Train net output #0: loss = 0.145442 (* 1 = 0.145442 loss)
I1030 13:08:01.495821  3774 solver.cpp:590] Iteration 52900, lr = 0.001
I1030 13:10:14.801842  3774 solver.cpp:243] Iteration 53000, loss = 0.094574
I1030 13:10:14.801939  3774 solver.cpp:259]     Train net output #0: loss = 0.094574 (* 1 = 0.094574 loss)
I1030 13:10:14.801959  3774 solver.cpp:590] Iteration 53000, lr = 0.001
I1030 13:12:30.538908  3774 solver.cpp:243] Iteration 53100, loss = 0.158252
I1030 13:12:30.539072  3774 solver.cpp:259]     Train net output #0: loss = 0.158252 (* 1 = 0.158252 loss)
I1030 13:12:30.539088  3774 solver.cpp:590] Iteration 53100, lr = 0.001
I1030 13:14:43.588989  3774 solver.cpp:243] Iteration 53200, loss = 0.0988256
I1030 13:14:43.589071  3774 solver.cpp:259]     Train net output #0: loss = 0.0988256 (* 1 = 0.0988256 loss)
I1030 13:14:43.589085  3774 solver.cpp:590] Iteration 53200, lr = 0.001
I1030 13:16:59.658109  3774 solver.cpp:243] Iteration 53300, loss = 0.137938
I1030 13:16:59.658185  3774 solver.cpp:259]     Train net output #0: loss = 0.137938 (* 1 = 0.137938 loss)
I1030 13:16:59.658195  3774 solver.cpp:590] Iteration 53300, lr = 0.001
I1030 13:17:27.477154  3774 solver.cpp:347] Iteration 53320, Testing net (#0)
I1030 13:20:37.088578  3774 solver.cpp:415]     Test net output #0: accuracy = 0.923638
I1030 13:20:37.088649  3774 solver.cpp:415]     Test net output #1: loss = 0.189466 (* 1 = 0.189466 loss)
I1030 13:22:23.182140  3774 solver.cpp:243] Iteration 53400, loss = 0.173786
I1030 13:22:23.182317  3774 solver.cpp:259]     Train net output #0: loss = 0.173786 (* 1 = 0.173786 loss)
I1030 13:22:23.182328  3774 solver.cpp:590] Iteration 53400, lr = 0.001
I1030 13:24:37.111516  3774 solver.cpp:243] Iteration 53500, loss = 0.114781
I1030 13:24:37.111608  3774 solver.cpp:259]     Train net output #0: loss = 0.114781 (* 1 = 0.114781 loss)
I1030 13:24:37.111618  3774 solver.cpp:590] Iteration 53500, lr = 0.001
I1030 13:26:26.274509  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 13:27:08.653774  3774 solver.cpp:243] Iteration 53600, loss = 0.122742
I1030 13:27:08.655539  3774 solver.cpp:259]     Train net output #0: loss = 0.122742 (* 1 = 0.122742 loss)
I1030 13:27:08.655589  3774 solver.cpp:590] Iteration 53600, lr = 0.001
I1030 13:29:44.733029  3774 solver.cpp:243] Iteration 53700, loss = 0.161647
I1030 13:29:44.733109  3774 solver.cpp:259]     Train net output #0: loss = 0.161647 (* 1 = 0.161647 loss)
I1030 13:29:44.733119  3774 solver.cpp:590] Iteration 53700, lr = 0.001
I1030 13:32:01.719775  3774 solver.cpp:243] Iteration 53800, loss = 0.19511
I1030 13:32:01.719883  3774 solver.cpp:259]     Train net output #0: loss = 0.19511 (* 1 = 0.19511 loss)
I1030 13:32:01.719904  3774 solver.cpp:590] Iteration 53800, lr = 0.001
I1030 13:34:12.215780  3774 solver.cpp:243] Iteration 53900, loss = 0.174541
I1030 13:34:12.215929  3774 solver.cpp:259]     Train net output #0: loss = 0.174541 (* 1 = 0.174541 loss)
I1030 13:34:12.215942  3774 solver.cpp:590] Iteration 53900, lr = 0.001
I1030 13:36:23.298236  3774 solver.cpp:243] Iteration 54000, loss = 0.165784
I1030 13:36:23.298363  3774 solver.cpp:259]     Train net output #0: loss = 0.165784 (* 1 = 0.165784 loss)
I1030 13:36:23.298375  3774 solver.cpp:590] Iteration 54000, lr = 0.001
I1030 13:38:31.788316  3774 solver.cpp:243] Iteration 54100, loss = 0.159287
I1030 13:38:31.788424  3774 solver.cpp:259]     Train net output #0: loss = 0.159287 (* 1 = 0.159287 loss)
I1030 13:38:31.788436  3774 solver.cpp:590] Iteration 54100, lr = 0.001
I1030 13:40:40.454790  3774 solver.cpp:243] Iteration 54200, loss = 0.253123
I1030 13:40:40.454888  3774 solver.cpp:259]     Train net output #0: loss = 0.253123 (* 1 = 0.253123 loss)
I1030 13:40:40.454900  3774 solver.cpp:590] Iteration 54200, lr = 0.001
I1030 13:42:54.497994  3774 solver.cpp:243] Iteration 54300, loss = 0.108934
I1030 13:42:54.498088  3774 solver.cpp:259]     Train net output #0: loss = 0.108934 (* 1 = 0.108934 loss)
I1030 13:42:54.498108  3774 solver.cpp:590] Iteration 54300, lr = 0.001
I1030 13:45:05.959060  3774 solver.cpp:243] Iteration 54400, loss = 0.186027
I1030 13:45:05.959146  3774 solver.cpp:259]     Train net output #0: loss = 0.186027 (* 1 = 0.186027 loss)
I1030 13:45:05.959154  3774 solver.cpp:590] Iteration 54400, lr = 0.001
I1030 13:47:38.497076  3774 solver.cpp:243] Iteration 54500, loss = 0.116851
I1030 13:47:38.497161  3774 solver.cpp:259]     Train net output #0: loss = 0.116851 (* 1 = 0.116851 loss)
I1030 13:47:38.497172  3774 solver.cpp:590] Iteration 54500, lr = 0.001
I1030 13:49:19.285178  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 13:49:54.810905  3774 solver.cpp:243] Iteration 54600, loss = 0.154524
I1030 13:49:54.810991  3774 solver.cpp:259]     Train net output #0: loss = 0.154524 (* 1 = 0.154524 loss)
I1030 13:49:54.811003  3774 solver.cpp:590] Iteration 54600, lr = 0.001
I1030 13:52:10.253717  3774 solver.cpp:243] Iteration 54700, loss = 0.095375
I1030 13:52:10.253788  3774 solver.cpp:259]     Train net output #0: loss = 0.095375 (* 1 = 0.095375 loss)
I1030 13:52:10.253803  3774 solver.cpp:590] Iteration 54700, lr = 0.001
I1030 13:54:24.353087  3774 solver.cpp:243] Iteration 54800, loss = 0.166275
I1030 13:54:24.353178  3774 solver.cpp:259]     Train net output #0: loss = 0.166275 (* 1 = 0.166275 loss)
I1030 13:54:24.353188  3774 solver.cpp:590] Iteration 54800, lr = 0.001
I1030 13:56:42.064272  3774 solver.cpp:243] Iteration 54900, loss = 0.193574
I1030 13:56:42.064375  3774 solver.cpp:259]     Train net output #0: loss = 0.193574 (* 1 = 0.193574 loss)
I1030 13:56:42.064398  3774 solver.cpp:590] Iteration 54900, lr = 0.001
I1030 13:58:58.631973  3774 solver.cpp:243] Iteration 55000, loss = 0.0941034
I1030 13:58:58.632098  3774 solver.cpp:259]     Train net output #0: loss = 0.0941034 (* 1 = 0.0941034 loss)
I1030 13:58:58.632117  3774 solver.cpp:590] Iteration 55000, lr = 0.001
I1030 14:01:11.075791  3774 solver.cpp:243] Iteration 55100, loss = 0.0946233
I1030 14:01:11.085291  3774 solver.cpp:259]     Train net output #0: loss = 0.0946233 (* 1 = 0.0946233 loss)
I1030 14:01:11.085311  3774 solver.cpp:590] Iteration 55100, lr = 0.001
I1030 14:03:22.491165  3774 solver.cpp:243] Iteration 55200, loss = 0.188741
I1030 14:03:22.491267  3774 solver.cpp:259]     Train net output #0: loss = 0.188741 (* 1 = 0.188741 loss)
I1030 14:03:22.491283  3774 solver.cpp:590] Iteration 55200, lr = 0.001
I1030 14:05:42.939975  3774 solver.cpp:243] Iteration 55300, loss = 0.1631
I1030 14:05:42.940127  3774 solver.cpp:259]     Train net output #0: loss = 0.1631 (* 1 = 0.1631 loss)
I1030 14:05:42.940145  3774 solver.cpp:590] Iteration 55300, lr = 0.001
I1030 14:07:53.730790  3774 solver.cpp:243] Iteration 55400, loss = 0.144383
I1030 14:07:53.730904  3774 solver.cpp:259]     Train net output #0: loss = 0.144383 (* 1 = 0.144383 loss)
I1030 14:07:53.730921  3774 solver.cpp:590] Iteration 55400, lr = 0.001
I1030 14:10:08.153988  3774 solver.cpp:243] Iteration 55500, loss = 0.102242
I1030 14:10:08.154085  3774 solver.cpp:259]     Train net output #0: loss = 0.102242 (* 1 = 0.102242 loss)
I1030 14:10:08.154103  3774 solver.cpp:590] Iteration 55500, lr = 0.001
I1030 14:11:44.176556  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 14:12:18.508378  3774 solver.cpp:243] Iteration 55600, loss = 0.216924
I1030 14:12:18.508479  3774 solver.cpp:259]     Train net output #0: loss = 0.216924 (* 1 = 0.216924 loss)
I1030 14:12:18.508492  3774 solver.cpp:590] Iteration 55600, lr = 0.001
I1030 14:14:43.416920  3774 solver.cpp:243] Iteration 55700, loss = 0.120333
I1030 14:14:43.417032  3774 solver.cpp:259]     Train net output #0: loss = 0.120333 (* 1 = 0.120333 loss)
I1030 14:14:43.417044  3774 solver.cpp:590] Iteration 55700, lr = 0.001
I1030 14:17:02.905709  3774 solver.cpp:243] Iteration 55800, loss = 0.174706
I1030 14:17:02.905797  3774 solver.cpp:259]     Train net output #0: loss = 0.174706 (* 1 = 0.174706 loss)
I1030 14:17:02.905809  3774 solver.cpp:590] Iteration 55800, lr = 0.001
I1030 14:19:16.761706  3774 solver.cpp:243] Iteration 55900, loss = 0.165681
I1030 14:19:16.761868  3774 solver.cpp:259]     Train net output #0: loss = 0.165682 (* 1 = 0.165682 loss)
I1030 14:19:16.761881  3774 solver.cpp:590] Iteration 55900, lr = 0.001
I1030 14:21:36.007283  3774 solver.cpp:243] Iteration 56000, loss = 0.109083
I1030 14:21:36.007378  3774 solver.cpp:259]     Train net output #0: loss = 0.109083 (* 1 = 0.109083 loss)
I1030 14:21:36.007402  3774 solver.cpp:590] Iteration 56000, lr = 0.001
I1030 14:23:54.099323  3774 solver.cpp:243] Iteration 56100, loss = 0.083715
I1030 14:23:54.099540  3774 solver.cpp:259]     Train net output #0: loss = 0.0837151 (* 1 = 0.0837151 loss)
I1030 14:23:54.099556  3774 solver.cpp:590] Iteration 56100, lr = 0.001
I1030 14:26:15.226371  3774 solver.cpp:243] Iteration 56200, loss = 0.17363
I1030 14:26:15.226485  3774 solver.cpp:259]     Train net output #0: loss = 0.17363 (* 1 = 0.17363 loss)
I1030 14:26:15.226495  3774 solver.cpp:590] Iteration 56200, lr = 0.001
I1030 14:28:42.155369  3774 solver.cpp:243] Iteration 56300, loss = 0.169454
I1030 14:28:42.155468  3774 solver.cpp:259]     Train net output #0: loss = 0.169454 (* 1 = 0.169454 loss)
I1030 14:28:42.155483  3774 solver.cpp:590] Iteration 56300, lr = 0.001
I1030 14:30:58.530194  3774 solver.cpp:243] Iteration 56400, loss = 0.121499
I1030 14:30:58.530278  3774 solver.cpp:259]     Train net output #0: loss = 0.121499 (* 1 = 0.121499 loss)
I1030 14:30:58.530292  3774 solver.cpp:590] Iteration 56400, lr = 0.001
I1030 14:33:13.117544  3774 solver.cpp:243] Iteration 56500, loss = 0.153085
I1030 14:33:13.117643  3774 solver.cpp:259]     Train net output #0: loss = 0.153085 (* 1 = 0.153085 loss)
I1030 14:33:13.117653  3774 solver.cpp:590] Iteration 56500, lr = 0.001
I1030 14:34:51.964715  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 14:35:25.850162  3774 solver.cpp:243] Iteration 56600, loss = 0.167383
I1030 14:35:25.850221  3774 solver.cpp:259]     Train net output #0: loss = 0.167383 (* 1 = 0.167383 loss)
I1030 14:35:25.850230  3774 solver.cpp:590] Iteration 56600, lr = 0.001
I1030 14:37:45.914755  3774 solver.cpp:243] Iteration 56700, loss = 0.090216
I1030 14:37:45.914849  3774 solver.cpp:259]     Train net output #0: loss = 0.0902161 (* 1 = 0.0902161 loss)
I1030 14:37:45.914870  3774 solver.cpp:590] Iteration 56700, lr = 0.001
I1030 14:40:05.615960  3774 solver.cpp:243] Iteration 56800, loss = 0.117523
I1030 14:40:05.616062  3774 solver.cpp:259]     Train net output #0: loss = 0.117523 (* 1 = 0.117523 loss)
I1030 14:40:05.616077  3774 solver.cpp:590] Iteration 56800, lr = 0.001
I1030 14:42:27.280025  3774 solver.cpp:243] Iteration 56900, loss = 0.11947
I1030 14:42:27.281561  3774 solver.cpp:259]     Train net output #0: loss = 0.11947 (* 1 = 0.11947 loss)
I1030 14:42:27.281615  3774 solver.cpp:590] Iteration 56900, lr = 0.001
I1030 14:44:44.807013  3774 solver.cpp:243] Iteration 57000, loss = 0.165047
I1030 14:44:44.807114  3774 solver.cpp:259]     Train net output #0: loss = 0.165047 (* 1 = 0.165047 loss)
I1030 14:44:44.807135  3774 solver.cpp:590] Iteration 57000, lr = 0.001
I1030 14:47:10.601238  3774 solver.cpp:243] Iteration 57100, loss = 0.152912
I1030 14:47:10.601333  3774 solver.cpp:259]     Train net output #0: loss = 0.152912 (* 1 = 0.152912 loss)
I1030 14:47:10.601354  3774 solver.cpp:590] Iteration 57100, lr = 0.001
I1030 14:49:30.687461  3774 solver.cpp:243] Iteration 57200, loss = 0.141661
I1030 14:49:30.687533  3774 solver.cpp:259]     Train net output #0: loss = 0.141661 (* 1 = 0.141661 loss)
I1030 14:49:30.687543  3774 solver.cpp:590] Iteration 57200, lr = 0.001
I1030 14:51:48.071096  3774 solver.cpp:243] Iteration 57300, loss = 0.152725
I1030 14:51:48.071159  3774 solver.cpp:259]     Train net output #0: loss = 0.152725 (* 1 = 0.152725 loss)
I1030 14:51:48.071168  3774 solver.cpp:590] Iteration 57300, lr = 0.001
I1030 14:54:06.370471  3774 solver.cpp:243] Iteration 57400, loss = 0.265677
I1030 14:54:06.370564  3774 solver.cpp:259]     Train net output #0: loss = 0.265677 (* 1 = 0.265677 loss)
I1030 14:54:06.370584  3774 solver.cpp:590] Iteration 57400, lr = 0.001
I1030 14:56:29.514575  3774 solver.cpp:243] Iteration 57500, loss = 0.130415
I1030 14:56:29.514644  3774 solver.cpp:259]     Train net output #0: loss = 0.130415 (* 1 = 0.130415 loss)
I1030 14:56:29.514654  3774 solver.cpp:590] Iteration 57500, lr = 0.001
I1030 14:58:18.967939  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 14:58:58.080473  3774 solver.cpp:243] Iteration 57600, loss = 0.150122
I1030 14:58:58.080637  3774 solver.cpp:259]     Train net output #0: loss = 0.150122 (* 1 = 0.150122 loss)
I1030 14:58:58.080651  3774 solver.cpp:590] Iteration 57600, lr = 0.001
I1030 15:01:13.801573  3774 solver.cpp:243] Iteration 57700, loss = 0.167213
I1030 15:01:13.801635  3774 solver.cpp:259]     Train net output #0: loss = 0.167213 (* 1 = 0.167213 loss)
I1030 15:01:13.801643  3774 solver.cpp:590] Iteration 57700, lr = 0.001
I1030 15:03:27.628012  3774 solver.cpp:243] Iteration 57800, loss = 0.118153
I1030 15:03:27.628166  3774 solver.cpp:259]     Train net output #0: loss = 0.118153 (* 1 = 0.118153 loss)
I1030 15:03:27.628180  3774 solver.cpp:590] Iteration 57800, lr = 0.001
I1030 15:05:38.715400  3774 solver.cpp:243] Iteration 57900, loss = 0.199146
I1030 15:05:38.715490  3774 solver.cpp:259]     Train net output #0: loss = 0.199146 (* 1 = 0.199146 loss)
I1030 15:05:38.715509  3774 solver.cpp:590] Iteration 57900, lr = 0.001
I1030 15:07:51.599611  3774 solver.cpp:243] Iteration 58000, loss = 0.128862
I1030 15:07:51.599773  3774 solver.cpp:259]     Train net output #0: loss = 0.128862 (* 1 = 0.128862 loss)
I1030 15:07:51.599786  3774 solver.cpp:590] Iteration 58000, lr = 0.001
I1030 15:10:05.904898  3774 solver.cpp:243] Iteration 58100, loss = 0.165374
I1030 15:10:05.905052  3774 solver.cpp:259]     Train net output #0: loss = 0.165374 (* 1 = 0.165374 loss)
I1030 15:10:05.905066  3774 solver.cpp:590] Iteration 58100, lr = 0.001
I1030 15:12:19.260321  3774 solver.cpp:243] Iteration 58200, loss = 0.111459
I1030 15:12:19.260411  3774 solver.cpp:259]     Train net output #0: loss = 0.111459 (* 1 = 0.111459 loss)
I1030 15:12:19.260431  3774 solver.cpp:590] Iteration 58200, lr = 0.001
I1030 15:14:31.303910  3774 solver.cpp:243] Iteration 58300, loss = 0.122788
I1030 15:14:31.303997  3774 solver.cpp:259]     Train net output #0: loss = 0.122788 (* 1 = 0.122788 loss)
I1030 15:14:31.304016  3774 solver.cpp:590] Iteration 58300, lr = 0.001
I1030 15:16:42.336122  3774 solver.cpp:243] Iteration 58400, loss = 0.136828
I1030 15:16:42.336202  3774 solver.cpp:259]     Train net output #0: loss = 0.136828 (* 1 = 0.136828 loss)
I1030 15:16:42.336211  3774 solver.cpp:590] Iteration 58400, lr = 0.001
I1030 15:18:55.792165  3774 solver.cpp:243] Iteration 58500, loss = 0.0816982
I1030 15:18:55.792249  3774 solver.cpp:259]     Train net output #0: loss = 0.0816983 (* 1 = 0.0816983 loss)
I1030 15:18:55.792259  3774 solver.cpp:590] Iteration 58500, lr = 0.001
I1030 15:20:32.778574  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 15:21:06.924762  3774 solver.cpp:243] Iteration 58600, loss = 0.177966
I1030 15:21:06.924896  3774 solver.cpp:259]     Train net output #0: loss = 0.177966 (* 1 = 0.177966 loss)
I1030 15:21:06.924906  3774 solver.cpp:590] Iteration 58600, lr = 0.001
I1030 15:23:17.316858  3774 solver.cpp:243] Iteration 58700, loss = 0.117824
I1030 15:23:17.316972  3774 solver.cpp:259]     Train net output #0: loss = 0.117824 (* 1 = 0.117824 loss)
I1030 15:23:17.316985  3774 solver.cpp:590] Iteration 58700, lr = 0.001
I1030 15:25:27.543067  3774 solver.cpp:243] Iteration 58800, loss = 0.195725
I1030 15:25:27.543157  3774 solver.cpp:259]     Train net output #0: loss = 0.195725 (* 1 = 0.195725 loss)
I1030 15:25:27.543176  3774 solver.cpp:590] Iteration 58800, lr = 0.001
I1030 15:27:44.066187  3774 solver.cpp:243] Iteration 58900, loss = 0.150419
I1030 15:27:44.066282  3774 solver.cpp:259]     Train net output #0: loss = 0.150419 (* 1 = 0.150419 loss)
I1030 15:27:44.066303  3774 solver.cpp:590] Iteration 58900, lr = 0.001
I1030 15:29:57.095800  3774 solver.cpp:243] Iteration 59000, loss = 0.225291
I1030 15:29:57.095958  3774 solver.cpp:259]     Train net output #0: loss = 0.225291 (* 1 = 0.225291 loss)
I1030 15:29:57.095971  3774 solver.cpp:590] Iteration 59000, lr = 0.001
I1030 15:32:07.821892  3774 solver.cpp:243] Iteration 59100, loss = 0.090951
I1030 15:32:07.821985  3774 solver.cpp:259]     Train net output #0: loss = 0.090951 (* 1 = 0.090951 loss)
I1030 15:32:07.822005  3774 solver.cpp:590] Iteration 59100, lr = 0.001
I1030 15:34:23.446741  3774 solver.cpp:243] Iteration 59200, loss = 0.12337
I1030 15:34:23.446851  3774 solver.cpp:259]     Train net output #0: loss = 0.12337 (* 1 = 0.12337 loss)
I1030 15:34:23.446864  3774 solver.cpp:590] Iteration 59200, lr = 0.001
I1030 15:36:52.284080  3774 solver.cpp:243] Iteration 59300, loss = 0.110114
I1030 15:36:52.284157  3774 solver.cpp:259]     Train net output #0: loss = 0.110114 (* 1 = 0.110114 loss)
I1030 15:36:52.284167  3774 solver.cpp:590] Iteration 59300, lr = 0.001
I1030 15:39:17.931298  3774 solver.cpp:243] Iteration 59400, loss = 0.139117
I1030 15:39:17.931363  3774 solver.cpp:259]     Train net output #0: loss = 0.139117 (* 1 = 0.139117 loss)
I1030 15:39:17.931373  3774 solver.cpp:590] Iteration 59400, lr = 0.001
I1030 15:41:29.256538  3774 solver.cpp:243] Iteration 59500, loss = 0.108098
I1030 15:41:29.256642  3774 solver.cpp:259]     Train net output #0: loss = 0.108098 (* 1 = 0.108098 loss)
I1030 15:41:29.256666  3774 solver.cpp:590] Iteration 59500, lr = 0.001
I1030 15:43:06.918032  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 15:43:40.724406  3774 solver.cpp:243] Iteration 59600, loss = 0.1428
I1030 15:43:40.724504  3774 solver.cpp:259]     Train net output #0: loss = 0.1428 (* 1 = 0.1428 loss)
I1030 15:43:40.724524  3774 solver.cpp:590] Iteration 59600, lr = 0.001
I1030 15:45:52.300115  3774 solver.cpp:243] Iteration 59700, loss = 0.148531
I1030 15:45:52.300214  3774 solver.cpp:259]     Train net output #0: loss = 0.148531 (* 1 = 0.148531 loss)
I1030 15:45:52.300230  3774 solver.cpp:590] Iteration 59700, lr = 0.001
I1030 15:48:04.793042  3774 solver.cpp:243] Iteration 59800, loss = 0.134857
I1030 15:48:04.793171  3774 solver.cpp:259]     Train net output #0: loss = 0.134857 (* 1 = 0.134857 loss)
I1030 15:48:04.793185  3774 solver.cpp:590] Iteration 59800, lr = 0.001
I1030 15:50:23.428436  3774 solver.cpp:243] Iteration 59900, loss = 0.108325
I1030 15:50:23.428503  3774 solver.cpp:259]     Train net output #0: loss = 0.108325 (* 1 = 0.108325 loss)
I1030 15:50:23.428511  3774 solver.cpp:590] Iteration 59900, lr = 0.001
I1030 15:52:25.719667  3774 solver.cpp:347] Iteration 59985, Testing net (#0)
I1030 15:55:52.398566  3774 solver.cpp:415]     Test net output #0: accuracy = 0.924077
I1030 15:55:52.398666  3774 solver.cpp:415]     Test net output #1: loss = 0.189965 (* 1 = 0.189965 loss)
I1030 15:56:13.553354  3774 solver.cpp:243] Iteration 60000, loss = 0.108825
I1030 15:56:13.553397  3774 solver.cpp:259]     Train net output #0: loss = 0.108825 (* 1 = 0.108825 loss)
I1030 15:56:13.553408  3774 solver.cpp:590] Iteration 60000, lr = 0.001
I1030 15:58:47.907290  3774 solver.cpp:243] Iteration 60100, loss = 0.144061
I1030 15:58:47.907413  3774 solver.cpp:259]     Train net output #0: loss = 0.144061 (* 1 = 0.144061 loss)
I1030 15:58:47.907423  3774 solver.cpp:590] Iteration 60100, lr = 0.001
I1030 16:00:58.800528  3774 solver.cpp:243] Iteration 60200, loss = 0.153376
I1030 16:00:58.800617  3774 solver.cpp:259]     Train net output #0: loss = 0.153376 (* 1 = 0.153376 loss)
I1030 16:00:58.800637  3774 solver.cpp:590] Iteration 60200, lr = 0.001
I1030 16:03:15.416453  3774 solver.cpp:243] Iteration 60300, loss = 0.129161
I1030 16:03:15.416604  3774 solver.cpp:259]     Train net output #0: loss = 0.129161 (* 1 = 0.129161 loss)
I1030 16:03:15.416615  3774 solver.cpp:590] Iteration 60300, lr = 0.001
I1030 16:05:23.601281  3774 solver.cpp:243] Iteration 60400, loss = 0.129187
I1030 16:05:23.601438  3774 solver.cpp:259]     Train net output #0: loss = 0.129187 (* 1 = 0.129187 loss)
I1030 16:05:23.601450  3774 solver.cpp:590] Iteration 60400, lr = 0.001
I1030 16:07:18.322222  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 16:07:31.999270  3774 solver.cpp:243] Iteration 60500, loss = 0.175579
I1030 16:07:31.999310  3774 solver.cpp:259]     Train net output #0: loss = 0.175579 (* 1 = 0.175579 loss)
I1030 16:07:31.999318  3774 solver.cpp:590] Iteration 60500, lr = 0.001
I1030 16:10:28.151726  3774 solver.cpp:243] Iteration 60600, loss = 0.145906
I1030 16:10:28.151821  3774 solver.cpp:259]     Train net output #0: loss = 0.145907 (* 1 = 0.145907 loss)
I1030 16:10:28.151841  3774 solver.cpp:590] Iteration 60600, lr = 0.001
I1030 16:12:38.865176  3774 solver.cpp:243] Iteration 60700, loss = 0.165842
I1030 16:12:38.865284  3774 solver.cpp:259]     Train net output #0: loss = 0.165842 (* 1 = 0.165842 loss)
I1030 16:12:38.865305  3774 solver.cpp:590] Iteration 60700, lr = 0.001
I1030 16:14:50.394418  3774 solver.cpp:243] Iteration 60800, loss = 0.304061
I1030 16:14:50.394577  3774 solver.cpp:259]     Train net output #0: loss = 0.304061 (* 1 = 0.304061 loss)
I1030 16:14:50.394589  3774 solver.cpp:590] Iteration 60800, lr = 0.001
I1030 16:17:00.920253  3774 solver.cpp:243] Iteration 60900, loss = 0.127862
I1030 16:17:00.920361  3774 solver.cpp:259]     Train net output #0: loss = 0.127862 (* 1 = 0.127862 loss)
I1030 16:17:00.920374  3774 solver.cpp:590] Iteration 60900, lr = 0.001
I1030 16:19:17.954427  3774 solver.cpp:243] Iteration 61000, loss = 0.0848656
I1030 16:19:17.954514  3774 solver.cpp:259]     Train net output #0: loss = 0.0848657 (* 1 = 0.0848657 loss)
I1030 16:19:17.954524  3774 solver.cpp:590] Iteration 61000, lr = 0.001
I1030 16:21:47.239953  3774 solver.cpp:243] Iteration 61100, loss = 0.0690066
I1030 16:21:47.240202  3774 solver.cpp:259]     Train net output #0: loss = 0.0690067 (* 1 = 0.0690067 loss)
I1030 16:21:47.240242  3774 solver.cpp:590] Iteration 61100, lr = 0.001
I1030 16:24:07.186353  3774 solver.cpp:243] Iteration 61200, loss = 0.154173
I1030 16:24:07.186440  3774 solver.cpp:259]     Train net output #0: loss = 0.154173 (* 1 = 0.154173 loss)
I1030 16:24:07.186460  3774 solver.cpp:590] Iteration 61200, lr = 0.001
I1030 16:26:28.722587  3774 solver.cpp:243] Iteration 61300, loss = 0.0793477
I1030 16:26:28.722683  3774 solver.cpp:259]     Train net output #0: loss = 0.0793478 (* 1 = 0.0793478 loss)
I1030 16:26:28.722697  3774 solver.cpp:590] Iteration 61300, lr = 0.001
I1030 16:28:53.151892  3774 solver.cpp:243] Iteration 61400, loss = 0.145469
I1030 16:28:53.152027  3774 solver.cpp:259]     Train net output #0: loss = 0.145469 (* 1 = 0.145469 loss)
I1030 16:28:53.152040  3774 solver.cpp:590] Iteration 61400, lr = 0.001
I1030 16:30:53.074117  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 16:31:08.349931  3774 solver.cpp:243] Iteration 61500, loss = 0.12285
I1030 16:31:08.350095  3774 solver.cpp:259]     Train net output #0: loss = 0.12285 (* 1 = 0.12285 loss)
I1030 16:31:08.350154  3774 solver.cpp:590] Iteration 61500, lr = 0.001
I1030 16:33:22.030696  3774 solver.cpp:243] Iteration 61600, loss = 0.156445
I1030 16:33:22.030788  3774 solver.cpp:259]     Train net output #0: loss = 0.156445 (* 1 = 0.156445 loss)
I1030 16:33:22.030808  3774 solver.cpp:590] Iteration 61600, lr = 0.001
I1030 16:35:36.771868  3774 solver.cpp:243] Iteration 61700, loss = 0.170975
I1030 16:35:36.771965  3774 solver.cpp:259]     Train net output #0: loss = 0.170975 (* 1 = 0.170975 loss)
I1030 16:35:36.771975  3774 solver.cpp:590] Iteration 61700, lr = 0.001
I1030 16:37:51.392824  3774 solver.cpp:243] Iteration 61800, loss = 0.174993
I1030 16:37:51.392902  3774 solver.cpp:259]     Train net output #0: loss = 0.174993 (* 1 = 0.174993 loss)
I1030 16:37:51.392912  3774 solver.cpp:590] Iteration 61800, lr = 0.001
I1030 16:40:04.984050  3774 solver.cpp:243] Iteration 61900, loss = 0.149771
I1030 16:40:04.984163  3774 solver.cpp:259]     Train net output #0: loss = 0.149771 (* 1 = 0.149771 loss)
I1030 16:40:04.984174  3774 solver.cpp:590] Iteration 61900, lr = 0.001
I1030 16:42:25.607599  3774 solver.cpp:243] Iteration 62000, loss = 0.0792233
I1030 16:42:25.607678  3774 solver.cpp:259]     Train net output #0: loss = 0.0792233 (* 1 = 0.0792233 loss)
I1030 16:42:25.607688  3774 solver.cpp:590] Iteration 62000, lr = 0.001
I1030 16:44:40.552054  3774 solver.cpp:243] Iteration 62100, loss = 0.135166
I1030 16:44:40.552151  3774 solver.cpp:259]     Train net output #0: loss = 0.135166 (* 1 = 0.135166 loss)
I1030 16:44:40.552165  3774 solver.cpp:590] Iteration 62100, lr = 0.001
I1030 16:46:59.371811  3774 solver.cpp:243] Iteration 62200, loss = 0.175534
I1030 16:46:59.371963  3774 solver.cpp:259]     Train net output #0: loss = 0.175534 (* 1 = 0.175534 loss)
I1030 16:46:59.371989  3774 solver.cpp:590] Iteration 62200, lr = 0.001
I1030 16:49:16.897078  3774 solver.cpp:243] Iteration 62300, loss = 0.117383
I1030 16:49:16.897158  3774 solver.cpp:259]     Train net output #0: loss = 0.117383 (* 1 = 0.117383 loss)
I1030 16:49:16.897171  3774 solver.cpp:590] Iteration 62300, lr = 0.001
I1030 16:51:30.135692  3774 solver.cpp:243] Iteration 62400, loss = 0.293544
I1030 16:51:30.135840  3774 solver.cpp:259]     Train net output #0: loss = 0.293544 (* 1 = 0.293544 loss)
I1030 16:51:30.135854  3774 solver.cpp:590] Iteration 62400, lr = 0.001
I1030 16:53:42.323987  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 16:53:58.981647  3774 solver.cpp:243] Iteration 62500, loss = 0.171779
I1030 16:53:58.981729  3774 solver.cpp:259]     Train net output #0: loss = 0.171779 (* 1 = 0.171779 loss)
I1030 16:53:58.981744  3774 solver.cpp:590] Iteration 62500, lr = 0.001
I1030 16:56:18.763360  3774 solver.cpp:243] Iteration 62600, loss = 0.0977498
I1030 16:56:18.763461  3774 solver.cpp:259]     Train net output #0: loss = 0.0977499 (* 1 = 0.0977499 loss)
I1030 16:56:18.763486  3774 solver.cpp:590] Iteration 62600, lr = 0.001
I1030 16:58:34.352643  3774 solver.cpp:243] Iteration 62700, loss = 0.10274
I1030 16:58:34.352769  3774 solver.cpp:259]     Train net output #0: loss = 0.10274 (* 1 = 0.10274 loss)
I1030 16:58:34.352780  3774 solver.cpp:590] Iteration 62700, lr = 0.001
I1030 17:00:46.438354  3774 solver.cpp:243] Iteration 62800, loss = 0.166863
I1030 17:00:46.438446  3774 solver.cpp:259]     Train net output #0: loss = 0.166863 (* 1 = 0.166863 loss)
I1030 17:00:46.438469  3774 solver.cpp:590] Iteration 62800, lr = 0.001
I1030 17:03:01.728230  3774 solver.cpp:243] Iteration 62900, loss = 0.229186
I1030 17:03:01.728325  3774 solver.cpp:259]     Train net output #0: loss = 0.229186 (* 1 = 0.229186 loss)
I1030 17:03:01.728338  3774 solver.cpp:590] Iteration 62900, lr = 0.001
I1030 17:05:16.352291  3774 solver.cpp:243] Iteration 63000, loss = 0.124311
I1030 17:05:16.352417  3774 solver.cpp:259]     Train net output #0: loss = 0.124311 (* 1 = 0.124311 loss)
I1030 17:05:16.352427  3774 solver.cpp:590] Iteration 63000, lr = 0.001
I1030 17:07:27.725882  3774 solver.cpp:243] Iteration 63100, loss = 0.104513
I1030 17:07:27.725960  3774 solver.cpp:259]     Train net output #0: loss = 0.104513 (* 1 = 0.104513 loss)
I1030 17:07:27.725970  3774 solver.cpp:590] Iteration 63100, lr = 0.001
I1030 17:09:37.534808  3774 solver.cpp:243] Iteration 63200, loss = 0.160489
I1030 17:09:37.534895  3774 solver.cpp:259]     Train net output #0: loss = 0.160489 (* 1 = 0.160489 loss)
I1030 17:09:37.534914  3774 solver.cpp:590] Iteration 63200, lr = 0.001
I1030 17:11:48.101435  3774 solver.cpp:243] Iteration 63300, loss = 0.0727278
I1030 17:11:48.101531  3774 solver.cpp:259]     Train net output #0: loss = 0.0727278 (* 1 = 0.0727278 loss)
I1030 17:11:48.101555  3774 solver.cpp:590] Iteration 63300, lr = 0.001
I1030 17:13:59.722136  3774 solver.cpp:243] Iteration 63400, loss = 0.120288
I1030 17:13:59.722232  3774 solver.cpp:259]     Train net output #0: loss = 0.120288 (* 1 = 0.120288 loss)
I1030 17:13:59.722246  3774 solver.cpp:590] Iteration 63400, lr = 0.001
I1030 17:15:55.645421  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 17:16:10.150355  3774 solver.cpp:243] Iteration 63500, loss = 0.0866402
I1030 17:16:10.150393  3774 solver.cpp:259]     Train net output #0: loss = 0.0866402 (* 1 = 0.0866402 loss)
I1030 17:16:10.150401  3774 solver.cpp:590] Iteration 63500, lr = 0.001
I1030 17:18:25.762887  3774 solver.cpp:243] Iteration 63600, loss = 0.183415
I1030 17:18:25.762975  3774 solver.cpp:259]     Train net output #0: loss = 0.183415 (* 1 = 0.183415 loss)
I1030 17:18:25.762995  3774 solver.cpp:590] Iteration 63600, lr = 0.001
I1030 17:20:38.544913  3774 solver.cpp:243] Iteration 63700, loss = 0.128298
I1030 17:20:38.544996  3774 solver.cpp:259]     Train net output #0: loss = 0.128298 (* 1 = 0.128298 loss)
I1030 17:20:38.545006  3774 solver.cpp:590] Iteration 63700, lr = 0.001
I1030 17:22:49.185001  3774 solver.cpp:243] Iteration 63800, loss = 0.0828149
I1030 17:22:49.185086  3774 solver.cpp:259]     Train net output #0: loss = 0.0828149 (* 1 = 0.0828149 loss)
I1030 17:22:49.185094  3774 solver.cpp:590] Iteration 63800, lr = 0.001
I1030 17:25:01.630509  3774 solver.cpp:243] Iteration 63900, loss = 0.15807
I1030 17:25:01.630597  3774 solver.cpp:259]     Train net output #0: loss = 0.15807 (* 1 = 0.15807 loss)
I1030 17:25:01.630617  3774 solver.cpp:590] Iteration 63900, lr = 0.001
I1030 17:27:13.521785  3774 solver.cpp:243] Iteration 64000, loss = 0.116002
I1030 17:27:13.521862  3774 solver.cpp:259]     Train net output #0: loss = 0.116003 (* 1 = 0.116003 loss)
I1030 17:27:13.521872  3774 solver.cpp:590] Iteration 64000, lr = 0.001
I1030 17:29:33.878295  3774 solver.cpp:243] Iteration 64100, loss = 0.196368
I1030 17:29:33.878401  3774 solver.cpp:259]     Train net output #0: loss = 0.196368 (* 1 = 0.196368 loss)
I1030 17:29:33.878422  3774 solver.cpp:590] Iteration 64100, lr = 0.001
I1030 17:31:46.228457  3774 solver.cpp:243] Iteration 64200, loss = 0.0906865
I1030 17:31:46.228549  3774 solver.cpp:259]     Train net output #0: loss = 0.0906866 (* 1 = 0.0906866 loss)
I1030 17:31:46.228569  3774 solver.cpp:590] Iteration 64200, lr = 0.001
I1030 17:33:58.147565  3774 solver.cpp:243] Iteration 64300, loss = 0.0794444
I1030 17:33:58.147656  3774 solver.cpp:259]     Train net output #0: loss = 0.0794444 (* 1 = 0.0794444 loss)
I1030 17:33:58.147676  3774 solver.cpp:590] Iteration 64300, lr = 0.001
I1030 17:36:11.549885  3774 solver.cpp:243] Iteration 64400, loss = 0.144741
I1030 17:36:11.549976  3774 solver.cpp:259]     Train net output #0: loss = 0.144741 (* 1 = 0.144741 loss)
I1030 17:36:11.549996  3774 solver.cpp:590] Iteration 64400, lr = 0.001
I1030 17:38:08.315958  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 17:38:22.454053  3774 solver.cpp:243] Iteration 64500, loss = 0.213366
I1030 17:38:22.454092  3774 solver.cpp:259]     Train net output #0: loss = 0.213366 (* 1 = 0.213366 loss)
I1030 17:38:22.454099  3774 solver.cpp:590] Iteration 64500, lr = 0.001
I1030 17:40:34.037207  3774 solver.cpp:243] Iteration 64600, loss = 0.116653
I1030 17:40:34.037281  3774 solver.cpp:259]     Train net output #0: loss = 0.116653 (* 1 = 0.116653 loss)
I1030 17:40:34.037291  3774 solver.cpp:590] Iteration 64600, lr = 0.001
I1030 17:42:49.192893  3774 solver.cpp:243] Iteration 64700, loss = 0.137377
I1030 17:42:49.192955  3774 solver.cpp:259]     Train net output #0: loss = 0.137377 (* 1 = 0.137377 loss)
I1030 17:42:49.192963  3774 solver.cpp:590] Iteration 64700, lr = 0.001
I1030 17:45:01.108782  3774 solver.cpp:243] Iteration 64800, loss = 0.127694
I1030 17:45:01.108865  3774 solver.cpp:259]     Train net output #0: loss = 0.127694 (* 1 = 0.127694 loss)
I1030 17:45:01.108875  3774 solver.cpp:590] Iteration 64800, lr = 0.001
I1030 17:47:18.796828  3774 solver.cpp:243] Iteration 64900, loss = 0.0905806
I1030 17:47:18.796895  3774 solver.cpp:259]     Train net output #0: loss = 0.0905806 (* 1 = 0.0905806 loss)
I1030 17:47:18.796905  3774 solver.cpp:590] Iteration 64900, lr = 0.001
I1030 17:49:53.642537  3774 solver.cpp:243] Iteration 65000, loss = 0.126712
I1030 17:49:53.642690  3774 solver.cpp:259]     Train net output #0: loss = 0.126712 (* 1 = 0.126712 loss)
I1030 17:49:53.642700  3774 solver.cpp:590] Iteration 65000, lr = 0.001
I1030 17:52:23.724831  3774 solver.cpp:243] Iteration 65100, loss = 0.123076
I1030 17:52:23.724915  3774 solver.cpp:259]     Train net output #0: loss = 0.123077 (* 1 = 0.123077 loss)
I1030 17:52:23.724925  3774 solver.cpp:590] Iteration 65100, lr = 0.001
I1030 17:54:48.980180  3774 solver.cpp:243] Iteration 65200, loss = 0.147227
I1030 17:54:48.980281  3774 solver.cpp:259]     Train net output #0: loss = 0.147227 (* 1 = 0.147227 loss)
I1030 17:54:48.980293  3774 solver.cpp:590] Iteration 65200, lr = 0.001
I1030 17:57:58.890645  3774 solver.cpp:243] Iteration 65300, loss = 0.0957004
I1030 17:57:58.890728  3774 solver.cpp:259]     Train net output #0: loss = 0.0957005 (* 1 = 0.0957005 loss)
I1030 17:57:58.890738  3774 solver.cpp:590] Iteration 65300, lr = 0.001
I1030 18:00:33.812774  3774 solver.cpp:243] Iteration 65400, loss = 0.1036
I1030 18:00:33.812858  3774 solver.cpp:259]     Train net output #0: loss = 0.1036 (* 1 = 0.1036 loss)
I1030 18:00:33.812868  3774 solver.cpp:590] Iteration 65400, lr = 0.001
I1030 18:02:35.052814  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 18:02:49.694592  3774 solver.cpp:243] Iteration 65500, loss = 0.175771
I1030 18:02:49.694630  3774 solver.cpp:259]     Train net output #0: loss = 0.175771 (* 1 = 0.175771 loss)
I1030 18:02:49.694640  3774 solver.cpp:590] Iteration 65500, lr = 0.001
I1030 18:05:44.569548  3774 solver.cpp:243] Iteration 65600, loss = 0.149217
I1030 18:05:44.569646  3774 solver.cpp:259]     Train net output #0: loss = 0.149217 (* 1 = 0.149217 loss)
I1030 18:05:44.569666  3774 solver.cpp:590] Iteration 65600, lr = 0.001
I1030 18:08:02.959789  3774 solver.cpp:243] Iteration 65700, loss = 0.104953
I1030 18:08:02.974037  3774 solver.cpp:259]     Train net output #0: loss = 0.104954 (* 1 = 0.104954 loss)
I1030 18:08:02.974067  3774 solver.cpp:590] Iteration 65700, lr = 0.001
I1030 18:10:15.735764  3774 solver.cpp:243] Iteration 65800, loss = 0.139482
I1030 18:10:15.735858  3774 solver.cpp:259]     Train net output #0: loss = 0.139482 (* 1 = 0.139482 loss)
I1030 18:10:15.735874  3774 solver.cpp:590] Iteration 65800, lr = 0.001
I1030 18:12:26.829705  3774 solver.cpp:243] Iteration 65900, loss = 0.1566
I1030 18:12:26.829829  3774 solver.cpp:259]     Train net output #0: loss = 0.1566 (* 1 = 0.1566 loss)
I1030 18:12:26.829841  3774 solver.cpp:590] Iteration 65900, lr = 0.001
I1030 18:14:48.049286  3774 solver.cpp:243] Iteration 66000, loss = 0.112569
I1030 18:14:48.049382  3774 solver.cpp:259]     Train net output #0: loss = 0.112569 (* 1 = 0.112569 loss)
I1030 18:14:48.049403  3774 solver.cpp:590] Iteration 66000, lr = 0.001
I1030 18:17:02.809157  3774 solver.cpp:243] Iteration 66100, loss = 0.191319
I1030 18:17:02.809286  3774 solver.cpp:259]     Train net output #0: loss = 0.191319 (* 1 = 0.191319 loss)
I1030 18:17:02.809316  3774 solver.cpp:590] Iteration 66100, lr = 0.001
I1030 18:19:17.046512  3774 solver.cpp:243] Iteration 66200, loss = 0.227435
I1030 18:19:17.046603  3774 solver.cpp:259]     Train net output #0: loss = 0.227435 (* 1 = 0.227435 loss)
I1030 18:19:17.046623  3774 solver.cpp:590] Iteration 66200, lr = 0.001
I1030 18:21:28.094393  3774 solver.cpp:243] Iteration 66300, loss = 0.122639
I1030 18:21:28.094485  3774 solver.cpp:259]     Train net output #0: loss = 0.122639 (* 1 = 0.122639 loss)
I1030 18:21:28.094506  3774 solver.cpp:590] Iteration 66300, lr = 0.001
I1030 18:23:41.386158  3774 solver.cpp:243] Iteration 66400, loss = 0.129907
I1030 18:23:41.388680  3774 solver.cpp:259]     Train net output #0: loss = 0.129907 (* 1 = 0.129907 loss)
I1030 18:23:41.388746  3774 solver.cpp:590] Iteration 66400, lr = 0.001
I1030 18:25:43.058527  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 18:25:58.081938  3774 solver.cpp:243] Iteration 66500, loss = 0.163142
I1030 18:25:58.081984  3774 solver.cpp:259]     Train net output #0: loss = 0.163142 (* 1 = 0.163142 loss)
I1030 18:25:58.081997  3774 solver.cpp:590] Iteration 66500, lr = 0.001
I1030 18:28:17.688419  3774 solver.cpp:243] Iteration 66600, loss = 0.140444
I1030 18:28:17.688520  3774 solver.cpp:259]     Train net output #0: loss = 0.140444 (* 1 = 0.140444 loss)
I1030 18:28:17.688539  3774 solver.cpp:590] Iteration 66600, lr = 0.001
I1030 18:29:29.024718  3774 solver.cpp:468] Snapshotting to binary proto file examples/nuclei/multi_class_nuclei/use_multi_class/use_multi_class_nuclei_big_1_iter_66650.caffemodel
I1030 18:29:29.869633  3774 solver.cpp:753] Snapshotting solver state to binary proto file examples/nuclei/multi_class_nuclei/use_multi_class/use_multi_class_nuclei_big_1_iter_66650.solverstate
I1030 18:29:29.870478  3774 solver.cpp:347] Iteration 66650, Testing net (#0)
I1030 18:33:36.688880  3774 solver.cpp:415]     Test net output #0: accuracy = 0.926332
I1030 18:33:36.688966  3774 solver.cpp:415]     Test net output #1: loss = 0.185856 (* 1 = 0.185856 loss)
I1030 18:35:00.298115  3774 solver.cpp:243] Iteration 66700, loss = 0.206796
I1030 18:35:00.298213  3774 solver.cpp:259]     Train net output #0: loss = 0.206796 (* 1 = 0.206796 loss)
I1030 18:35:00.298233  3774 solver.cpp:590] Iteration 66700, lr = 0.001
I1030 18:37:34.683979  3774 solver.cpp:243] Iteration 66800, loss = 0.108019
I1030 18:37:34.684072  3774 solver.cpp:259]     Train net output #0: loss = 0.108019 (* 1 = 0.108019 loss)
I1030 18:37:34.684097  3774 solver.cpp:590] Iteration 66800, lr = 0.001
I1030 18:39:54.957254  3774 solver.cpp:243] Iteration 66900, loss = 0.141784
I1030 18:39:54.957412  3774 solver.cpp:259]     Train net output #0: loss = 0.141784 (* 1 = 0.141784 loss)
I1030 18:39:54.957435  3774 solver.cpp:590] Iteration 66900, lr = 0.001
I1030 18:42:06.531005  3774 solver.cpp:243] Iteration 67000, loss = 0.109578
I1030 18:42:06.531106  3774 solver.cpp:259]     Train net output #0: loss = 0.109578 (* 1 = 0.109578 loss)
I1030 18:42:06.531121  3774 solver.cpp:590] Iteration 67000, lr = 0.001
I1030 18:44:16.054683  3774 solver.cpp:243] Iteration 67100, loss = 0.0914237
I1030 18:44:16.054841  3774 solver.cpp:259]     Train net output #0: loss = 0.0914237 (* 1 = 0.0914237 loss)
I1030 18:44:16.054853  3774 solver.cpp:590] Iteration 67100, lr = 0.001
I1030 18:46:24.619376  3774 solver.cpp:243] Iteration 67200, loss = 0.0927102
I1030 18:46:24.619465  3774 solver.cpp:259]     Train net output #0: loss = 0.0927102 (* 1 = 0.0927102 loss)
I1030 18:46:24.619485  3774 solver.cpp:590] Iteration 67200, lr = 0.001
I1030 18:48:36.062810  3774 solver.cpp:243] Iteration 67300, loss = 0.195823
I1030 18:48:36.062958  3774 solver.cpp:259]     Train net output #0: loss = 0.195823 (* 1 = 0.195823 loss)
I1030 18:48:36.062970  3774 solver.cpp:590] Iteration 67300, lr = 0.001
I1030 18:50:52.027683  3774 solver.cpp:243] Iteration 67400, loss = 0.0913012
I1030 18:50:52.027819  3774 solver.cpp:259]     Train net output #0: loss = 0.0913013 (* 1 = 0.0913013 loss)
I1030 18:50:52.027839  3774 solver.cpp:590] Iteration 67400, lr = 0.001
I1030 18:50:53.299796  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 18:53:02.385021  3774 solver.cpp:243] Iteration 67500, loss = 0.0970663
I1030 18:53:02.385107  3774 solver.cpp:259]     Train net output #0: loss = 0.0970664 (* 1 = 0.0970664 loss)
I1030 18:53:02.385118  3774 solver.cpp:590] Iteration 67500, lr = 0.001
I1030 18:55:18.110584  3774 solver.cpp:243] Iteration 67600, loss = 0.157036
I1030 18:55:18.110698  3774 solver.cpp:259]     Train net output #0: loss = 0.157036 (* 1 = 0.157036 loss)
I1030 18:55:18.110709  3774 solver.cpp:590] Iteration 67600, lr = 0.001
I1030 18:57:44.655064  3774 solver.cpp:243] Iteration 67700, loss = 0.123557
I1030 18:57:44.655228  3774 solver.cpp:259]     Train net output #0: loss = 0.123557 (* 1 = 0.123557 loss)
I1030 18:57:44.655241  3774 solver.cpp:590] Iteration 67700, lr = 0.001
I1030 18:59:57.798807  3774 solver.cpp:243] Iteration 67800, loss = 0.202977
I1030 18:59:57.798924  3774 solver.cpp:259]     Train net output #0: loss = 0.202977 (* 1 = 0.202977 loss)
I1030 18:59:57.798935  3774 solver.cpp:590] Iteration 67800, lr = 0.001
I1030 19:02:11.735541  3774 solver.cpp:243] Iteration 67900, loss = 0.182814
I1030 19:02:11.735652  3774 solver.cpp:259]     Train net output #0: loss = 0.182814 (* 1 = 0.182814 loss)
I1030 19:02:11.735662  3774 solver.cpp:590] Iteration 67900, lr = 0.001
I1030 19:04:22.109977  3774 solver.cpp:243] Iteration 68000, loss = 0.228406
I1030 19:04:22.110069  3774 solver.cpp:259]     Train net output #0: loss = 0.228406 (* 1 = 0.228406 loss)
I1030 19:04:22.110090  3774 solver.cpp:590] Iteration 68000, lr = 0.001
I1030 19:06:39.713266  3774 solver.cpp:243] Iteration 68100, loss = 0.103777
I1030 19:06:39.713343  3774 solver.cpp:259]     Train net output #0: loss = 0.103777 (* 1 = 0.103777 loss)
I1030 19:06:39.713359  3774 solver.cpp:590] Iteration 68100, lr = 0.001
I1030 19:09:04.454036  3774 solver.cpp:243] Iteration 68200, loss = 0.140732
I1030 19:09:04.454115  3774 solver.cpp:259]     Train net output #0: loss = 0.140733 (* 1 = 0.140733 loss)
I1030 19:09:04.454126  3774 solver.cpp:590] Iteration 68200, lr = 0.001
I1030 19:11:16.411164  3774 solver.cpp:243] Iteration 68300, loss = 0.203773
I1030 19:11:16.411228  3774 solver.cpp:259]     Train net output #0: loss = 0.203773 (* 1 = 0.203773 loss)
I1030 19:11:16.411242  3774 solver.cpp:590] Iteration 68300, lr = 0.001
I1030 19:13:25.757568  3774 solver.cpp:243] Iteration 68400, loss = 0.081308
I1030 19:13:25.757664  3774 solver.cpp:259]     Train net output #0: loss = 0.0813083 (* 1 = 0.0813083 loss)
I1030 19:13:25.757688  3774 solver.cpp:590] Iteration 68400, lr = 0.001
I1030 19:13:26.935029  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 19:15:36.587812  3774 solver.cpp:243] Iteration 68500, loss = 0.141134
I1030 19:15:36.587918  3774 solver.cpp:259]     Train net output #0: loss = 0.141135 (* 1 = 0.141135 loss)
I1030 19:15:36.587939  3774 solver.cpp:590] Iteration 68500, lr = 0.001
I1030 19:17:49.782795  3774 solver.cpp:243] Iteration 68600, loss = 0.127519
I1030 19:17:49.782889  3774 solver.cpp:259]     Train net output #0: loss = 0.127519 (* 1 = 0.127519 loss)
I1030 19:17:49.782907  3774 solver.cpp:590] Iteration 68600, lr = 0.001
I1030 19:20:01.366592  3774 solver.cpp:243] Iteration 68700, loss = 0.12398
I1030 19:20:01.366686  3774 solver.cpp:259]     Train net output #0: loss = 0.123981 (* 1 = 0.123981 loss)
I1030 19:20:01.366700  3774 solver.cpp:590] Iteration 68700, lr = 0.001
I1030 19:22:15.332000  3774 solver.cpp:243] Iteration 68800, loss = 0.163323
I1030 19:22:15.332160  3774 solver.cpp:259]     Train net output #0: loss = 0.163324 (* 1 = 0.163324 loss)
I1030 19:22:15.332181  3774 solver.cpp:590] Iteration 68800, lr = 0.001
I1030 19:24:29.024503  3774 solver.cpp:243] Iteration 68900, loss = 0.14115
I1030 19:24:29.024617  3774 solver.cpp:259]     Train net output #0: loss = 0.14115 (* 1 = 0.14115 loss)
I1030 19:24:29.024683  3774 solver.cpp:590] Iteration 68900, lr = 0.001
I1030 19:26:50.145812  3774 solver.cpp:243] Iteration 69000, loss = 0.0780206
I1030 19:26:50.148972  3774 solver.cpp:259]     Train net output #0: loss = 0.0780208 (* 1 = 0.0780208 loss)
I1030 19:26:50.149046  3774 solver.cpp:590] Iteration 69000, lr = 0.001
I1030 19:29:19.066243  3774 solver.cpp:243] Iteration 69100, loss = 0.181856
I1030 19:29:19.066356  3774 solver.cpp:259]     Train net output #0: loss = 0.181856 (* 1 = 0.181856 loss)
I1030 19:29:19.066370  3774 solver.cpp:590] Iteration 69100, lr = 0.001
I1030 19:31:34.220051  3774 solver.cpp:243] Iteration 69200, loss = 0.194192
I1030 19:31:34.220201  3774 solver.cpp:259]     Train net output #0: loss = 0.194192 (* 1 = 0.194192 loss)
I1030 19:31:34.220214  3774 solver.cpp:590] Iteration 69200, lr = 0.001
I1030 19:34:09.412755  3774 solver.cpp:243] Iteration 69300, loss = 0.12826
I1030 19:34:09.412912  3774 solver.cpp:259]     Train net output #0: loss = 0.12826 (* 1 = 0.12826 loss)
I1030 19:34:09.412947  3774 solver.cpp:590] Iteration 69300, lr = 0.001
I1030 19:36:25.620064  3774 solver.cpp:243] Iteration 69400, loss = 0.188056
I1030 19:36:25.620151  3774 solver.cpp:259]     Train net output #0: loss = 0.188056 (* 1 = 0.188056 loss)
I1030 19:36:25.620167  3774 solver.cpp:590] Iteration 69400, lr = 0.001
I1030 19:36:27.024273  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 19:38:34.847599  3774 solver.cpp:243] Iteration 69500, loss = 0.179997
I1030 19:38:34.847712  3774 solver.cpp:259]     Train net output #0: loss = 0.179998 (* 1 = 0.179998 loss)
I1030 19:38:34.847723  3774 solver.cpp:590] Iteration 69500, lr = 0.001
I1030 19:40:47.554066  3774 solver.cpp:243] Iteration 69600, loss = 0.218449
I1030 19:40:47.554150  3774 solver.cpp:259]     Train net output #0: loss = 0.218449 (* 1 = 0.218449 loss)
I1030 19:40:47.554162  3774 solver.cpp:590] Iteration 69600, lr = 0.001
I1030 19:42:59.456679  3774 solver.cpp:243] Iteration 69700, loss = 0.137111
I1030 19:42:59.456774  3774 solver.cpp:259]     Train net output #0: loss = 0.137111 (* 1 = 0.137111 loss)
I1030 19:42:59.456794  3774 solver.cpp:590] Iteration 69700, lr = 0.001
I1030 19:45:09.065400  3774 solver.cpp:243] Iteration 69800, loss = 0.132415
I1030 19:45:09.065491  3774 solver.cpp:259]     Train net output #0: loss = 0.132415 (* 1 = 0.132415 loss)
I1030 19:45:09.065511  3774 solver.cpp:590] Iteration 69800, lr = 0.001
I1030 19:47:20.057610  3774 solver.cpp:243] Iteration 69900, loss = 0.130345
I1030 19:47:20.057692  3774 solver.cpp:259]     Train net output #0: loss = 0.130345 (* 1 = 0.130345 loss)
I1030 19:47:20.057709  3774 solver.cpp:590] Iteration 69900, lr = 0.001
I1030 19:49:38.430477  3774 solver.cpp:243] Iteration 70000, loss = 0.143571
I1030 19:49:38.430634  3774 solver.cpp:259]     Train net output #0: loss = 0.143571 (* 1 = 0.143571 loss)
I1030 19:49:38.430652  3774 solver.cpp:590] Iteration 70000, lr = 0.001
I1030 19:51:54.456811  3774 solver.cpp:243] Iteration 70100, loss = 0.232981
I1030 19:51:54.456890  3774 solver.cpp:259]     Train net output #0: loss = 0.232981 (* 1 = 0.232981 loss)
I1030 19:51:54.456899  3774 solver.cpp:590] Iteration 70100, lr = 0.001
I1030 19:54:07.967222  3774 solver.cpp:243] Iteration 70200, loss = 0.116277
I1030 19:54:07.967300  3774 solver.cpp:259]     Train net output #0: loss = 0.116278 (* 1 = 0.116278 loss)
I1030 19:54:07.967311  3774 solver.cpp:590] Iteration 70200, lr = 0.001
I1030 19:56:24.285012  3774 solver.cpp:243] Iteration 70300, loss = 0.132526
I1030 19:56:24.286075  3774 solver.cpp:259]     Train net output #0: loss = 0.132526 (* 1 = 0.132526 loss)
I1030 19:56:24.286135  3774 solver.cpp:590] Iteration 70300, lr = 0.001
I1030 19:58:41.835153  3774 solver.cpp:243] Iteration 70400, loss = 0.128192
I1030 19:58:41.835445  3774 solver.cpp:259]     Train net output #0: loss = 0.128192 (* 1 = 0.128192 loss)
I1030 19:58:41.835556  3774 solver.cpp:590] Iteration 70400, lr = 0.001
I1030 19:58:42.989979  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 20:00:59.458096  3774 solver.cpp:243] Iteration 70500, loss = 0.19898
I1030 20:00:59.458187  3774 solver.cpp:259]     Train net output #0: loss = 0.19898 (* 1 = 0.19898 loss)
I1030 20:00:59.458207  3774 solver.cpp:590] Iteration 70500, lr = 0.001
I1030 20:03:11.578405  3774 solver.cpp:243] Iteration 70600, loss = 0.105271
I1030 20:03:11.578500  3774 solver.cpp:259]     Train net output #0: loss = 0.105271 (* 1 = 0.105271 loss)
I1030 20:03:11.578510  3774 solver.cpp:590] Iteration 70600, lr = 0.001
I1030 20:05:31.342175  3774 solver.cpp:243] Iteration 70700, loss = 0.134163
I1030 20:05:31.342416  3774 solver.cpp:259]     Train net output #0: loss = 0.134163 (* 1 = 0.134163 loss)
I1030 20:05:31.342464  3774 solver.cpp:590] Iteration 70700, lr = 0.001
I1030 20:07:49.691812  3774 solver.cpp:243] Iteration 70800, loss = 0.204648
I1030 20:07:49.691901  3774 solver.cpp:259]     Train net output #0: loss = 0.204648 (* 1 = 0.204648 loss)
I1030 20:07:49.691915  3774 solver.cpp:590] Iteration 70800, lr = 0.001
I1030 20:10:07.861696  3774 solver.cpp:243] Iteration 70900, loss = 0.207428
I1030 20:10:07.861778  3774 solver.cpp:259]     Train net output #0: loss = 0.207429 (* 1 = 0.207429 loss)
I1030 20:10:07.861794  3774 solver.cpp:590] Iteration 70900, lr = 0.001
I1030 20:12:24.952169  3774 solver.cpp:243] Iteration 71000, loss = 0.122348
I1030 20:12:24.952249  3774 solver.cpp:259]     Train net output #0: loss = 0.122349 (* 1 = 0.122349 loss)
I1030 20:12:24.952263  3774 solver.cpp:590] Iteration 71000, lr = 0.001
I1030 20:14:39.005592  3774 solver.cpp:243] Iteration 71100, loss = 0.131937
I1030 20:14:39.006036  3774 solver.cpp:259]     Train net output #0: loss = 0.131938 (* 1 = 0.131938 loss)
I1030 20:14:39.006181  3774 solver.cpp:590] Iteration 71100, lr = 0.001
I1030 20:17:06.026702  3774 solver.cpp:243] Iteration 71200, loss = 0.146992
I1030 20:17:06.026871  3774 solver.cpp:259]     Train net output #0: loss = 0.146992 (* 1 = 0.146992 loss)
I1030 20:17:06.026885  3774 solver.cpp:590] Iteration 71200, lr = 0.001
I1030 20:19:20.465394  3774 solver.cpp:243] Iteration 71300, loss = 0.149792
I1030 20:19:20.465488  3774 solver.cpp:259]     Train net output #0: loss = 0.149792 (* 1 = 0.149792 loss)
I1030 20:19:20.465508  3774 solver.cpp:590] Iteration 71300, lr = 0.001
I1030 20:21:36.152791  3774 solver.cpp:243] Iteration 71400, loss = 0.147309
I1030 20:21:36.152881  3774 solver.cpp:259]     Train net output #0: loss = 0.147309 (* 1 = 0.147309 loss)
I1030 20:21:36.152900  3774 solver.cpp:590] Iteration 71400, lr = 0.001
I1030 20:21:37.489900  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 20:23:48.692101  3774 solver.cpp:243] Iteration 71500, loss = 0.117672
I1030 20:23:48.692190  3774 solver.cpp:259]     Train net output #0: loss = 0.117672 (* 1 = 0.117672 loss)
I1030 20:23:48.692210  3774 solver.cpp:590] Iteration 71500, lr = 0.001
I1030 20:26:00.323927  3774 solver.cpp:243] Iteration 71600, loss = 0.176988
I1030 20:26:00.325337  3774 solver.cpp:259]     Train net output #0: loss = 0.176988 (* 1 = 0.176988 loss)
I1030 20:26:00.325352  3774 solver.cpp:590] Iteration 71600, lr = 0.001
I1030 20:28:16.901216  3774 solver.cpp:243] Iteration 71700, loss = 0.163222
I1030 20:28:16.901342  3774 solver.cpp:259]     Train net output #0: loss = 0.163222 (* 1 = 0.163222 loss)
I1030 20:28:16.901352  3774 solver.cpp:590] Iteration 71700, lr = 0.001
I1030 20:30:27.255875  3774 solver.cpp:243] Iteration 71800, loss = 0.142932
I1030 20:30:27.255965  3774 solver.cpp:259]     Train net output #0: loss = 0.142933 (* 1 = 0.142933 loss)
I1030 20:30:27.255985  3774 solver.cpp:590] Iteration 71800, lr = 0.001
I1030 20:32:38.436633  3774 solver.cpp:243] Iteration 71900, loss = 0.181453
I1030 20:32:38.436733  3774 solver.cpp:259]     Train net output #0: loss = 0.181453 (* 1 = 0.181453 loss)
I1030 20:32:38.436751  3774 solver.cpp:590] Iteration 71900, lr = 0.001
I1030 20:34:48.999249  3774 solver.cpp:243] Iteration 72000, loss = 0.177338
I1030 20:34:48.999339  3774 solver.cpp:259]     Train net output #0: loss = 0.177339 (* 1 = 0.177339 loss)
I1030 20:34:48.999359  3774 solver.cpp:590] Iteration 72000, lr = 0.001
I1030 20:36:59.608577  3774 solver.cpp:243] Iteration 72100, loss = 0.117204
I1030 20:36:59.608713  3774 solver.cpp:259]     Train net output #0: loss = 0.117204 (* 1 = 0.117204 loss)
I1030 20:36:59.608723  3774 solver.cpp:590] Iteration 72100, lr = 0.001
I1030 20:39:13.056922  3774 solver.cpp:243] Iteration 72200, loss = 0.217751
I1030 20:39:13.057010  3774 solver.cpp:259]     Train net output #0: loss = 0.217751 (* 1 = 0.217751 loss)
I1030 20:39:13.057020  3774 solver.cpp:590] Iteration 72200, lr = 0.001
I1030 20:41:25.857802  3774 solver.cpp:243] Iteration 72300, loss = 0.0828027
I1030 20:41:25.857957  3774 solver.cpp:259]     Train net output #0: loss = 0.0828029 (* 1 = 0.0828029 loss)
I1030 20:41:25.857970  3774 solver.cpp:590] Iteration 72300, lr = 0.001
I1030 20:43:39.136611  3774 solver.cpp:243] Iteration 72400, loss = 0.1026
I1030 20:43:39.136693  3774 solver.cpp:259]     Train net output #0: loss = 0.1026 (* 1 = 0.1026 loss)
I1030 20:43:39.136703  3774 solver.cpp:590] Iteration 72400, lr = 0.001
I1030 20:43:40.399121  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 20:45:49.724911  3774 solver.cpp:243] Iteration 72500, loss = 0.165781
I1030 20:45:49.724992  3774 solver.cpp:259]     Train net output #0: loss = 0.165782 (* 1 = 0.165782 loss)
I1030 20:45:49.725003  3774 solver.cpp:590] Iteration 72500, lr = 0.001
I1030 20:47:59.291442  3774 solver.cpp:243] Iteration 72600, loss = 0.121711
I1030 20:47:59.291534  3774 solver.cpp:259]     Train net output #0: loss = 0.121711 (* 1 = 0.121711 loss)
I1030 20:47:59.291554  3774 solver.cpp:590] Iteration 72600, lr = 0.001
I1030 20:50:10.334137  3774 solver.cpp:243] Iteration 72700, loss = 0.176602
I1030 20:50:10.334218  3774 solver.cpp:259]     Train net output #0: loss = 0.176602 (* 1 = 0.176602 loss)
I1030 20:50:10.334228  3774 solver.cpp:590] Iteration 72700, lr = 0.001
I1030 20:52:21.346276  3774 solver.cpp:243] Iteration 72800, loss = 0.0837114
I1030 20:52:21.346423  3774 solver.cpp:259]     Train net output #0: loss = 0.0837117 (* 1 = 0.0837117 loss)
I1030 20:52:21.346436  3774 solver.cpp:590] Iteration 72800, lr = 0.001
I1030 20:54:29.747136  3774 solver.cpp:243] Iteration 72900, loss = 0.142881
I1030 20:54:29.747289  3774 solver.cpp:259]     Train net output #0: loss = 0.142881 (* 1 = 0.142881 loss)
I1030 20:54:29.747303  3774 solver.cpp:590] Iteration 72900, lr = 0.001
I1030 20:56:38.742153  3774 solver.cpp:243] Iteration 73000, loss = 0.168462
I1030 20:56:38.742244  3774 solver.cpp:259]     Train net output #0: loss = 0.168462 (* 1 = 0.168462 loss)
I1030 20:56:38.742264  3774 solver.cpp:590] Iteration 73000, lr = 0.001
I1030 20:58:51.375998  3774 solver.cpp:243] Iteration 73100, loss = 0.116111
I1030 20:58:51.376088  3774 solver.cpp:259]     Train net output #0: loss = 0.116112 (* 1 = 0.116112 loss)
I1030 20:58:51.376108  3774 solver.cpp:590] Iteration 73100, lr = 0.001
I1030 21:01:01.262763  3774 solver.cpp:243] Iteration 73200, loss = 0.144169
I1030 21:01:01.262871  3774 solver.cpp:259]     Train net output #0: loss = 0.144169 (* 1 = 0.144169 loss)
I1030 21:01:01.262883  3774 solver.cpp:590] Iteration 73200, lr = 0.001
I1030 21:03:11.883229  3774 solver.cpp:243] Iteration 73300, loss = 0.131426
I1030 21:03:11.883322  3774 solver.cpp:259]     Train net output #0: loss = 0.131426 (* 1 = 0.131426 loss)
I1030 21:03:11.883345  3774 solver.cpp:590] Iteration 73300, lr = 0.001
I1030 21:03:29.797612  3774 solver.cpp:347] Iteration 73315, Testing net (#0)
I1030 21:07:07.224660  3774 solver.cpp:415]     Test net output #0: accuracy = 0.924437
I1030 21:07:07.224730  3774 solver.cpp:415]     Test net output #1: loss = 0.192993 (* 1 = 0.192993 loss)
I1030 21:07:16.561833  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 21:08:58.932047  3774 solver.cpp:243] Iteration 73400, loss = 0.140757
I1030 21:08:58.932139  3774 solver.cpp:259]     Train net output #0: loss = 0.140757 (* 1 = 0.140757 loss)
I1030 21:08:58.932159  3774 solver.cpp:590] Iteration 73400, lr = 0.001
I1030 21:11:12.833853  3774 solver.cpp:243] Iteration 73500, loss = 0.104097
I1030 21:11:12.833945  3774 solver.cpp:259]     Train net output #0: loss = 0.104097 (* 1 = 0.104097 loss)
I1030 21:11:12.833964  3774 solver.cpp:590] Iteration 73500, lr = 0.001
I1030 21:13:22.190310  3774 solver.cpp:243] Iteration 73600, loss = 0.157321
I1030 21:13:22.190400  3774 solver.cpp:259]     Train net output #0: loss = 0.157321 (* 1 = 0.157321 loss)
I1030 21:13:22.190421  3774 solver.cpp:590] Iteration 73600, lr = 0.001
I1030 21:15:31.703259  3774 solver.cpp:243] Iteration 73700, loss = 0.156193
I1030 21:15:31.703351  3774 solver.cpp:259]     Train net output #0: loss = 0.156194 (* 1 = 0.156194 loss)
I1030 21:15:31.703369  3774 solver.cpp:590] Iteration 73700, lr = 0.001
I1030 21:17:40.370911  3774 solver.cpp:243] Iteration 73800, loss = 0.150225
I1030 21:17:40.371001  3774 solver.cpp:259]     Train net output #0: loss = 0.150225 (* 1 = 0.150225 loss)
I1030 21:17:40.371021  3774 solver.cpp:590] Iteration 73800, lr = 0.001
I1030 21:19:52.348621  3774 solver.cpp:243] Iteration 73900, loss = 0.163394
I1030 21:19:52.348743  3774 solver.cpp:259]     Train net output #0: loss = 0.163394 (* 1 = 0.163394 loss)
I1030 21:19:52.348754  3774 solver.cpp:590] Iteration 73900, lr = 0.001
I1030 21:22:00.824874  3774 solver.cpp:243] Iteration 74000, loss = 0.138493
I1030 21:22:00.824954  3774 solver.cpp:259]     Train net output #0: loss = 0.138494 (* 1 = 0.138494 loss)
I1030 21:22:00.824965  3774 solver.cpp:590] Iteration 74000, lr = 0.001
I1030 21:24:06.840551  3774 solver.cpp:243] Iteration 74100, loss = 0.166363
I1030 21:24:06.840704  3774 solver.cpp:259]     Train net output #0: loss = 0.166364 (* 1 = 0.166364 loss)
I1030 21:24:06.840718  3774 solver.cpp:590] Iteration 74100, lr = 0.001
I1030 21:26:28.158133  3774 solver.cpp:243] Iteration 74200, loss = 0.186777
I1030 21:26:28.158303  3774 solver.cpp:259]     Train net output #0: loss = 0.186777 (* 1 = 0.186777 loss)
I1030 21:26:28.158316  3774 solver.cpp:590] Iteration 74200, lr = 0.001
I1030 21:28:49.105093  3774 solver.cpp:243] Iteration 74300, loss = 0.146232
I1030 21:28:49.105160  3774 solver.cpp:259]     Train net output #0: loss = 0.146232 (* 1 = 0.146232 loss)
I1030 21:28:49.105170  3774 solver.cpp:590] Iteration 74300, lr = 0.001
I1030 21:29:18.766736  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 21:31:02.831660  3774 solver.cpp:243] Iteration 74400, loss = 0.198184
I1030 21:31:02.831778  3774 solver.cpp:259]     Train net output #0: loss = 0.198184 (* 1 = 0.198184 loss)
I1030 21:31:02.831796  3774 solver.cpp:590] Iteration 74400, lr = 0.001
I1030 21:33:14.227269  3774 solver.cpp:243] Iteration 74500, loss = 0.0908505
I1030 21:33:14.227469  3774 solver.cpp:259]     Train net output #0: loss = 0.0908507 (* 1 = 0.0908507 loss)
I1030 21:33:14.227496  3774 solver.cpp:590] Iteration 74500, lr = 0.001
I1030 21:35:29.514991  3774 solver.cpp:243] Iteration 74600, loss = 0.0955397
I1030 21:35:29.515094  3774 solver.cpp:259]     Train net output #0: loss = 0.0955399 (* 1 = 0.0955399 loss)
I1030 21:35:29.515103  3774 solver.cpp:590] Iteration 74600, lr = 0.001
I1030 21:37:37.987738  3774 solver.cpp:243] Iteration 74700, loss = 0.168105
I1030 21:37:37.987828  3774 solver.cpp:259]     Train net output #0: loss = 0.168105 (* 1 = 0.168105 loss)
I1030 21:37:37.987843  3774 solver.cpp:590] Iteration 74700, lr = 0.001
I1030 21:39:47.884243  3774 solver.cpp:243] Iteration 74800, loss = 0.128375
I1030 21:39:47.884330  3774 solver.cpp:259]     Train net output #0: loss = 0.128375 (* 1 = 0.128375 loss)
I1030 21:39:47.884343  3774 solver.cpp:590] Iteration 74800, lr = 0.001
I1030 21:41:58.433756  3774 solver.cpp:243] Iteration 74900, loss = 0.207365
I1030 21:41:58.433830  3774 solver.cpp:259]     Train net output #0: loss = 0.207365 (* 1 = 0.207365 loss)
I1030 21:41:58.433843  3774 solver.cpp:590] Iteration 74900, lr = 0.001
I1030 21:44:05.527861  3774 solver.cpp:243] Iteration 75000, loss = 0.174483
I1030 21:44:05.527942  3774 solver.cpp:259]     Train net output #0: loss = 0.174483 (* 1 = 0.174483 loss)
I1030 21:44:05.527956  3774 solver.cpp:590] Iteration 75000, lr = 0.001
I1030 21:46:20.188424  3774 solver.cpp:243] Iteration 75100, loss = 0.111011
I1030 21:46:20.188501  3774 solver.cpp:259]     Train net output #0: loss = 0.111011 (* 1 = 0.111011 loss)
I1030 21:46:20.188513  3774 solver.cpp:590] Iteration 75100, lr = 0.001
I1030 21:48:34.955785  3774 solver.cpp:243] Iteration 75200, loss = 0.126645
I1030 21:48:34.956351  3774 solver.cpp:259]     Train net output #0: loss = 0.126645 (* 1 = 0.126645 loss)
I1030 21:48:34.956387  3774 solver.cpp:590] Iteration 75200, lr = 0.001
I1030 21:50:54.515290  3774 solver.cpp:243] Iteration 75300, loss = 0.131137
I1030 21:50:54.515373  3774 solver.cpp:259]     Train net output #0: loss = 0.131137 (* 1 = 0.131137 loss)
I1030 21:50:54.515383  3774 solver.cpp:590] Iteration 75300, lr = 0.001
I1030 21:51:24.760226  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 21:53:06.373862  3774 solver.cpp:243] Iteration 75400, loss = 0.134312
I1030 21:53:06.374007  3774 solver.cpp:259]     Train net output #0: loss = 0.134313 (* 1 = 0.134313 loss)
I1030 21:53:06.374023  3774 solver.cpp:590] Iteration 75400, lr = 0.001
I1030 21:55:22.048636  3774 solver.cpp:243] Iteration 75500, loss = 0.138504
I1030 21:55:22.048749  3774 solver.cpp:259]     Train net output #0: loss = 0.138504 (* 1 = 0.138504 loss)
I1030 21:55:22.048761  3774 solver.cpp:590] Iteration 75500, lr = 0.001
I1030 21:57:53.527803  3774 solver.cpp:243] Iteration 75600, loss = 0.101379
I1030 21:57:53.527871  3774 solver.cpp:259]     Train net output #0: loss = 0.101379 (* 1 = 0.101379 loss)
I1030 21:57:53.527884  3774 solver.cpp:590] Iteration 75600, lr = 0.001
I1030 22:00:14.014925  3774 solver.cpp:243] Iteration 75700, loss = 0.126889
I1030 22:00:14.015072  3774 solver.cpp:259]     Train net output #0: loss = 0.12689 (* 1 = 0.12689 loss)
I1030 22:00:14.015085  3774 solver.cpp:590] Iteration 75700, lr = 0.001
I1030 22:02:30.054291  3774 solver.cpp:243] Iteration 75800, loss = 0.0910124
I1030 22:02:30.054556  3774 solver.cpp:259]     Train net output #0: loss = 0.0910127 (* 1 = 0.0910127 loss)
I1030 22:02:30.054574  3774 solver.cpp:590] Iteration 75800, lr = 0.001
I1030 22:04:39.393066  3774 solver.cpp:243] Iteration 75900, loss = 0.0824528
I1030 22:04:39.393177  3774 solver.cpp:259]     Train net output #0: loss = 0.0824532 (* 1 = 0.0824532 loss)
I1030 22:04:39.393193  3774 solver.cpp:590] Iteration 75900, lr = 0.001
I1030 22:06:53.021001  3774 solver.cpp:243] Iteration 76000, loss = 0.171396
I1030 22:06:53.021118  3774 solver.cpp:259]     Train net output #0: loss = 0.171396 (* 1 = 0.171396 loss)
I1030 22:06:53.021128  3774 solver.cpp:590] Iteration 76000, lr = 0.001
I1030 22:09:02.477681  3774 solver.cpp:243] Iteration 76100, loss = 0.0888585
I1030 22:09:02.477841  3774 solver.cpp:259]     Train net output #0: loss = 0.0888589 (* 1 = 0.0888589 loss)
I1030 22:09:02.477855  3774 solver.cpp:590] Iteration 76100, lr = 0.001
I1030 22:11:15.388846  3774 solver.cpp:243] Iteration 76200, loss = 0.176088
I1030 22:11:15.389039  3774 solver.cpp:259]     Train net output #0: loss = 0.176088 (* 1 = 0.176088 loss)
I1030 22:11:15.389051  3774 solver.cpp:590] Iteration 76200, lr = 0.001
I1030 22:13:27.374444  3774 solver.cpp:243] Iteration 76300, loss = 0.156946
I1030 22:13:27.374541  3774 solver.cpp:259]     Train net output #0: loss = 0.156947 (* 1 = 0.156947 loss)
I1030 22:13:27.374559  3774 solver.cpp:590] Iteration 76300, lr = 0.001
I1030 22:13:57.119338  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 22:15:42.116416  3774 solver.cpp:243] Iteration 76400, loss = 0.161704
I1030 22:15:42.116562  3774 solver.cpp:259]     Train net output #0: loss = 0.161705 (* 1 = 0.161705 loss)
I1030 22:15:42.116575  3774 solver.cpp:590] Iteration 76400, lr = 0.001
I1030 22:17:52.270809  3774 solver.cpp:243] Iteration 76500, loss = 0.0812196
I1030 22:17:52.270889  3774 solver.cpp:259]     Train net output #0: loss = 0.0812199 (* 1 = 0.0812199 loss)
I1030 22:17:52.270900  3774 solver.cpp:590] Iteration 76500, lr = 0.001
I1030 22:20:05.128638  3774 solver.cpp:243] Iteration 76600, loss = 0.174585
I1030 22:20:05.128739  3774 solver.cpp:259]     Train net output #0: loss = 0.174585 (* 1 = 0.174585 loss)
I1030 22:20:05.128762  3774 solver.cpp:590] Iteration 76600, lr = 0.001
I1030 22:22:18.868731  3774 solver.cpp:243] Iteration 76700, loss = 0.186476
I1030 22:22:18.868834  3774 solver.cpp:259]     Train net output #0: loss = 0.186476 (* 1 = 0.186476 loss)
I1030 22:22:18.868844  3774 solver.cpp:590] Iteration 76700, lr = 0.001
I1030 22:24:39.715976  3774 solver.cpp:243] Iteration 76800, loss = 0.0949763
I1030 22:24:39.716097  3774 solver.cpp:259]     Train net output #0: loss = 0.0949766 (* 1 = 0.0949766 loss)
I1030 22:24:39.716107  3774 solver.cpp:590] Iteration 76800, lr = 0.001
I1030 22:27:00.595093  3774 solver.cpp:243] Iteration 76900, loss = 0.194215
I1030 22:27:00.595198  3774 solver.cpp:259]     Train net output #0: loss = 0.194215 (* 1 = 0.194215 loss)
I1030 22:27:00.595217  3774 solver.cpp:590] Iteration 76900, lr = 0.001
I1030 22:29:19.811812  3774 solver.cpp:243] Iteration 77000, loss = 0.159841
I1030 22:29:19.811899  3774 solver.cpp:259]     Train net output #0: loss = 0.159841 (* 1 = 0.159841 loss)
I1030 22:29:19.811918  3774 solver.cpp:590] Iteration 77000, lr = 0.001
I1030 22:31:32.659178  3774 solver.cpp:243] Iteration 77100, loss = 0.215038
I1030 22:31:32.659271  3774 solver.cpp:259]     Train net output #0: loss = 0.215038 (* 1 = 0.215038 loss)
I1030 22:31:32.659281  3774 solver.cpp:590] Iteration 77100, lr = 0.001
I1030 22:33:45.271141  3774 solver.cpp:243] Iteration 77200, loss = 0.162135
I1030 22:33:45.271226  3774 solver.cpp:259]     Train net output #0: loss = 0.162135 (* 1 = 0.162135 loss)
I1030 22:33:45.271246  3774 solver.cpp:590] Iteration 77200, lr = 0.001
I1030 22:35:58.492908  3774 solver.cpp:243] Iteration 77300, loss = 0.066656
I1030 22:35:58.492983  3774 solver.cpp:259]     Train net output #0: loss = 0.0666563 (* 1 = 0.0666563 loss)
I1030 22:35:58.492993  3774 solver.cpp:590] Iteration 77300, lr = 0.001
I1030 22:36:31.556057  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 22:38:21.671906  3774 solver.cpp:243] Iteration 77400, loss = 0.142288
I1030 22:38:21.672001  3774 solver.cpp:259]     Train net output #0: loss = 0.142288 (* 1 = 0.142288 loss)
I1030 22:38:21.672021  3774 solver.cpp:590] Iteration 77400, lr = 0.001
I1030 22:40:37.934746  3774 solver.cpp:243] Iteration 77500, loss = 0.14084
I1030 22:40:37.934828  3774 solver.cpp:259]     Train net output #0: loss = 0.14084 (* 1 = 0.14084 loss)
I1030 22:40:37.934837  3774 solver.cpp:590] Iteration 77500, lr = 0.001
I1030 22:42:52.634218  3774 solver.cpp:243] Iteration 77600, loss = 0.126551
I1030 22:42:52.634390  3774 solver.cpp:259]     Train net output #0: loss = 0.126552 (* 1 = 0.126552 loss)
I1030 22:42:52.634412  3774 solver.cpp:590] Iteration 77600, lr = 0.001
I1030 22:45:08.789939  3774 solver.cpp:243] Iteration 77700, loss = 0.117249
I1030 22:45:08.790060  3774 solver.cpp:259]     Train net output #0: loss = 0.117249 (* 1 = 0.117249 loss)
I1030 22:45:08.790071  3774 solver.cpp:590] Iteration 77700, lr = 0.001
I1030 22:47:22.709091  3774 solver.cpp:243] Iteration 77800, loss = 0.154339
I1030 22:47:22.709202  3774 solver.cpp:259]     Train net output #0: loss = 0.154339 (* 1 = 0.154339 loss)
I1030 22:47:22.709219  3774 solver.cpp:590] Iteration 77800, lr = 0.001
I1030 22:50:01.801820  3774 solver.cpp:243] Iteration 77900, loss = 0.0732002
I1030 22:50:01.801913  3774 solver.cpp:259]     Train net output #0: loss = 0.0732004 (* 1 = 0.0732004 loss)
I1030 22:50:01.801933  3774 solver.cpp:590] Iteration 77900, lr = 0.001
I1030 22:52:18.085135  3774 solver.cpp:243] Iteration 78000, loss = 0.153745
I1030 22:52:18.085289  3774 solver.cpp:259]     Train net output #0: loss = 0.153745 (* 1 = 0.153745 loss)
I1030 22:52:18.085386  3774 solver.cpp:590] Iteration 78000, lr = 0.001
I1030 22:54:38.277598  3774 solver.cpp:243] Iteration 78100, loss = 0.17162
I1030 22:54:38.277734  3774 solver.cpp:259]     Train net output #0: loss = 0.171621 (* 1 = 0.171621 loss)
I1030 22:54:38.277747  3774 solver.cpp:590] Iteration 78100, lr = 0.001
I1030 22:57:04.221743  3774 solver.cpp:243] Iteration 78200, loss = 0.104817
I1030 22:57:04.221842  3774 solver.cpp:259]     Train net output #0: loss = 0.104818 (* 1 = 0.104818 loss)
I1030 22:57:04.221858  3774 solver.cpp:590] Iteration 78200, lr = 0.001
I1030 22:59:28.712287  3774 solver.cpp:243] Iteration 78300, loss = 0.15602
I1030 22:59:28.712357  3774 solver.cpp:259]     Train net output #0: loss = 0.15602 (* 1 = 0.15602 loss)
I1030 22:59:28.712368  3774 solver.cpp:590] Iteration 78300, lr = 0.001
I1030 23:00:17.585392  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 23:02:27.347375  3774 solver.cpp:243] Iteration 78400, loss = 0.206118
I1030 23:02:27.347481  3774 solver.cpp:259]     Train net output #0: loss = 0.206118 (* 1 = 0.206118 loss)
I1030 23:02:27.347573  3774 solver.cpp:590] Iteration 78400, lr = 0.001
I1030 23:05:09.927417  3774 solver.cpp:243] Iteration 78500, loss = 0.131685
I1030 23:05:09.927561  3774 solver.cpp:259]     Train net output #0: loss = 0.131685 (* 1 = 0.131685 loss)
I1030 23:05:09.927595  3774 solver.cpp:590] Iteration 78500, lr = 0.001
I1030 23:07:50.717439  3774 solver.cpp:243] Iteration 78600, loss = 0.0880733
I1030 23:07:50.717525  3774 solver.cpp:259]     Train net output #0: loss = 0.0880736 (* 1 = 0.0880736 loss)
I1030 23:07:50.717540  3774 solver.cpp:590] Iteration 78600, lr = 0.001
I1030 23:10:30.185961  3774 solver.cpp:243] Iteration 78700, loss = 0.154108
I1030 23:10:30.186174  3774 solver.cpp:259]     Train net output #0: loss = 0.154109 (* 1 = 0.154109 loss)
I1030 23:10:30.186198  3774 solver.cpp:590] Iteration 78700, lr = 0.001
I1030 23:13:05.863150  3774 solver.cpp:243] Iteration 78800, loss = 0.150689
I1030 23:13:05.863260  3774 solver.cpp:259]     Train net output #0: loss = 0.15069 (* 1 = 0.15069 loss)
I1030 23:13:05.863293  3774 solver.cpp:590] Iteration 78800, lr = 0.001
I1030 23:15:55.506513  3774 solver.cpp:243] Iteration 78900, loss = 0.109805
I1030 23:15:55.506641  3774 solver.cpp:259]     Train net output #0: loss = 0.109805 (* 1 = 0.109805 loss)
I1030 23:15:55.506716  3774 solver.cpp:590] Iteration 78900, lr = 0.001
I1030 23:18:38.101462  3774 solver.cpp:243] Iteration 79000, loss = 0.0635674
I1030 23:18:38.101541  3774 solver.cpp:259]     Train net output #0: loss = 0.0635677 (* 1 = 0.0635677 loss)
I1030 23:18:38.101555  3774 solver.cpp:590] Iteration 79000, lr = 0.001
I1030 23:21:12.917852  3774 solver.cpp:243] Iteration 79100, loss = 0.147524
I1030 23:21:12.917928  3774 solver.cpp:259]     Train net output #0: loss = 0.147524 (* 1 = 0.147524 loss)
I1030 23:21:12.917939  3774 solver.cpp:590] Iteration 79100, lr = 0.001
I1030 23:24:02.605134  3774 solver.cpp:243] Iteration 79200, loss = 0.0631767
I1030 23:24:02.605206  3774 solver.cpp:259]     Train net output #0: loss = 0.063177 (* 1 = 0.063177 loss)
I1030 23:24:02.605216  3774 solver.cpp:590] Iteration 79200, lr = 0.001
I1030 23:26:44.506367  3774 solver.cpp:243] Iteration 79300, loss = 0.170535
I1030 23:26:44.506458  3774 solver.cpp:259]     Train net output #0: loss = 0.170535 (* 1 = 0.170535 loss)
I1030 23:26:44.506467  3774 solver.cpp:590] Iteration 79300, lr = 0.001
I1030 23:27:22.562577  3774 blocking_queue.cpp:50] Data layer prefetch queue empty
I1030 23:29:28.835052  3774 solver.cpp:243] Iteration 79400, loss = 0.188437
I1030 23:29:28.835175  3774 solver.cpp:259]     Train net output #0: loss = 0.188438 (* 1 = 0.188438 loss)
I1030 23:29:28.835186  3774 solver.cpp:590] Iteration 79400, lr = 0.001
I1030 23:32:07.415726  3774 solver.cpp:243] Iteration 79500, loss = 0.0825766
I1030 23:32:07.415817  3774 solver.cpp:259]     Train net output #0: loss = 0.0825768 (* 1 = 0.0825768 loss)
I1030 23:32:07.415837  3774 solver.cpp:590] Iteration 79500, lr = 0.001
I1030 23:35:01.602996  3774 solver.cpp:243] Iteration 79600, loss = 0.206046
I1030 23:35:01.603117  3774 solver.cpp:259]     Train net output #0: loss = 0.206047 (* 1 = 0.206047 loss)
I1030 23:35:01.603127  3774 solver.cpp:590] Iteration 79600, lr = 0.001
I1030 23:37:41.035405  3774 solver.cpp:243] Iteration 79700, loss = 0.148427
I1030 23:37:41.035483  3774 solver.cpp:259]     Train net output #0: loss = 0.148427 (* 1 = 0.148427 loss)
I1030 23:37:41.035536  3774 solver.cpp:590] Iteration 79700, lr = 0.001
I1030 23:40:14.751976  3774 solver.cpp:243] Iteration 79800, loss = 0.175472
I1030 23:40:14.752063  3774 solver.cpp:259]     Train net output #0: loss = 0.175472 (* 1 = 0.175472 loss)
I1030 23:40:14.752077  3774 solver.cpp:590] Iteration 79800, lr = 0.001
I1030 23:42:51.914181  3774 solver.cpp:243] Iteration 79900, loss = 0.177153
I1030 23:42:51.914281  3774 solver.cpp:259]     Train net output #0: loss = 0.177153 (* 1 = 0.177153 loss)
I1030 23:42:51.914348  3774 solver.cpp:590] Iteration 79900, lr = 0.001
